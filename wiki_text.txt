Humans (Homo sapiens, meaning "thinking man" or "wise man") or modern humans are the most common and widespread species of primate, and the last surviving species of the genus Homo. They are great apes characterized by their hairlessness, bipedalism, and high intelligence. Humans have large brains, enabling more advanced cognitive skills that enable them to thrive and adapt in varied environments, develop highly complex tools, and form complex social structures and civilizations. Humans are highly social, with individual humans tending to belong to a multi-layered network of cooperating, distinct, or even competing social groups – from families and peer groups to corporations and political states. As such, social interactions between humans have established a wide variety of values, social norms, languages, and traditions (collectively termed institutions), each of which bolsters human society. Humans are also highly curious, with the desire to understand and influence phenomena having motivated humanity's development of science, technology, philosophy, mythology, religion, and other frameworks of knowledge; humans also study themselves through such domains as anthropology, social science, history, psychology, and medicine. There are estimated to be more than eight billion living humans.

Although some scientists equate the term "humans" with all members of the genus Homo, in common usage it generally refers to Homo sapiens, the only extant member. All other members of the genus Homo, which are now extinct, are known as archaic humans, and the term "modern human" is used to distinguish Homo sapiens from archaic humans. Anatomically modern humans emerged around 300,000 years ago in Africa, evolving from Homo heidelbergensis or a similar species. Migrating out of Africa, they gradually replaced and interbred with local populations of archaic humans. Multiple hypotheses for the extinction of archaic human species such as Neanderthals include competition, violence, interbreeding with Homo sapiens, or inability to adapt to climate change. Humans began exhibiting behavioral modernity about 160,000–60,000 years ago. For most of their history, humans were nomadic hunter-gatherers. The Neolithic Revolution, which began in Southwest Asia around 13,000 years ago (and separately in a few other places), saw the emergence of agriculture and permanent human settlement; in turn, this led to the development of civilization and kickstarted a period of continuous (and ongoing) population growth and rapid technological change. Since then, a number of civilizations have risen and fallen, while a number of sociocultural and technological developments have resulted in significant changes to the human lifestyle.

Genes and the environment influence human biological variation in visible characteristics, physiology, disease susceptibility, mental abilities, body size, and life span. Though humans vary in many traits, humans are among the least genetically diverse species. Any two humans are at least 99.5% genetically similar. Humans are sexually dimorphic: generally, males have greater body strength and females have a higher body fat percentage. At puberty, humans develop secondary sex characteristics. Females are capable of pregnancy, usually between puberty, at around 12 years old, and menopause, around the age of 50. As omnivorous creatures, they are capable of consuming a wide variety of plant and animal material, and have used fire and other forms of heat to prepare and cook food since the time of Homo erectus. Humans can survive for up to eight weeks without food and several days without water. Humans are generally diurnal, sleeping on average seven to nine hours per day. Childbirth is dangerous, with a high risk of complications and death. Often, both the mother and the father provide care for their children, who are helpless at birth.

Humans have a large, highly developed, and complex prefrontal cortex, the region of the brain associated with higher cognition. Humans are highly intelligent and capable of episodic memory; they have flexible facial expressions, self-awareness, and a theory of mind. The human mind is capable of introspection, private thought, imagination, volition, and forming views on existence. This has allowed great technological advancements and complex tool development through complex reasoning and the transmission of knowledge to subsequent generations through language.

Humans have had a dramatic effect on the environment. They are apex predators, being rarely preyed upon by other species.[1] Human population growth, industrialization, land development, overconsumption and combustion of fossil fuels have led to environmental destruction and pollution that significantly contributes to the ongoing mass extinction of other forms of life.[2][3] Within the last century, humans have explored challenging environments such as Antarctica, the deep sea, and outer space.[4] Human habitation within these hostile environments is restrictive and expensive, typically limited in duration, and restricted to scientific, military, or industrial expeditions.[4] Humans have visited the Moon and made their presence known on other celestial bodies through human-made robotic spacecraft.[5][6][7] Since the early 20th century, there has been continuous human presence in Antarctica through research stations and, since 2000, in space through habitation on the International Space Station.[8]

Etymology and definition
Further information: Names for the human species and Human taxonomy

Carl Linnaeus coined the name Homo sapiens
All modern humans are classified into the species Homo sapiens, coined by Carl Linnaeus in his 1735 work Systema Naturae.[9] The generic name "Homo" is a learned 18th-century derivation from Latin homō, which refers to humans of either sex.[10][11] The word human can refer to all members of the Homo genus.[12] The name "Homo sapiens" means 'wise man' or 'knowledgeable man'.[13] There is disagreement if certain extinct members of the genus, namely Neanderthals, should be included as a separate species of humans or as a subspecies of H. sapiens.[12]

Human is a loanword of Middle English from Old French humain, ultimately from Latin hūmānus, the adjectival form of homō ('man' – in the sense of humanity).[14] The native English term man can refer to the species generally (a synonym for humanity) as well as to human males. It may also refer to individuals of either sex.[15]

Despite the fact that the word animal is colloquially used as an antonym for human,[16] and contrary to a common biological misconception, humans are animals.[17] The word person is often used interchangeably with human, but philosophical debate exists as to whether personhood applies to all humans or all sentient beings, and further if a human can lose personhood (such as by going into a persistent vegetative state).[18]

Evolution
Main article: Human evolution
Humans are apes (superfamily Hominoidea).[19] The lineage of apes that eventually gave rise to humans first split from gibbons (family Hylobatidae) and orangutans (genus Pongo), then gorillas (genus Gorilla), and finally, chimpanzees and bonobos (genus Pan). The last split, between the human and chimpanzee–bonobo lineages, took place around 8–4 million years ago, in the late Miocene epoch.[20][21] During this split, chromosome 2 was formed from the joining of two other chromosomes, leaving humans with only 23 pairs of chromosomes, compared to 24 for the other apes.[22] Following their split with chimpanzees and bonobos, the hominins diversified into many species and at least two distinct genera. All but one of these lineages – representing the genus Homo and its sole extant species Homo sapiens – are now extinct.[23]


Reconstruction of Lucy, the first Australopithecus afarensis skeleton found
The genus Homo evolved from Australopithecus.[24][25] Though fossils from the transition are scarce, the earliest members of Homo share several key traits with Australopithecus.[26][27] The earliest record of Homo is the 2.8 million-year-old specimen LD 350-1 from Ethiopia, and the earliest named species are Homo habilis and Homo rudolfensis which evolved by 2.3 million years ago.[27] H. erectus (the African variant is sometimes called H. ergaster) evolved 2 million years ago and was the first archaic human species to leave Africa and disperse across Eurasia.[28] H. erectus also was the first to evolve a characteristically human body plan. Homo sapiens emerged in Africa around 300,000 years ago from a species commonly designated as either H. heidelbergensis or H. rhodesiensis, the descendants of H. erectus that remained in Africa.[29] H. sapiens migrated out of the continent, gradually replacing or interbreeding with local populations of archaic humans.[30][31][32] Humans began exhibiting behavioral modernity about 160,000–70,000 years ago,[33] and possibly earlier.[34] This development was likely selected amidst natural climate change in Middle to Late Pleistocene Africa.[35]

The "out of Africa" migration took place in at least two waves, the first around 130,000 to 100,000 years ago, the second (Southern Dispersal) around 70,000 to 50,000 years ago.[36][37] H. sapiens proceeded to colonize all the continents and larger islands, arriving in Eurasia 125,000 years ago,[38][39] Australia around 65,000 years ago,[40] the Americas around 15,000 years ago, and remote islands such as Hawaii, Easter Island, Madagascar, and New Zealand in the years 300 to 1280 CE.[41][42]

Human evolution was not a simple linear or branched progression but involved interbreeding between related species.[43][44][45] Genomic research has shown that hybridization between substantially diverged lineages was common in human evolution.[46] DNA evidence suggests that several genes of Neanderthal origin are present among all non sub-Saharan-African populations, and Neanderthals and other hominins, such as Denisovans, may have contributed up to 6% of their genome to present-day non sub-Saharan-African humans.[43][47][48]

Human evolution is characterized by a number of morphological, developmental, physiological, and behavioral changes that have taken place since the split between the last common ancestor of humans and chimpanzees. The most significant of these adaptations are hairlessness,[49] obligate bipedalism, increased brain size and decreased sexual dimorphism (neoteny). The relationship between all these changes is the subject of ongoing debate.[50]

Hominoidea (hominoids, apes)	
Hylobatidae (gibbons)

Hominidae (hominids, great apes)	
Ponginae	
Pongo (orangutans)	
Pongo abelii

Pongo tapanuliensis

Pongo pygmaeus

Homininae (hominines)	
Gorillini	
Gorilla (gorillas)	
Gorilla gorilla

Gorilla beringei

Hominini (hominins)	
Panina	
Pan (chimpanzees)	
Pan troglodytes

Pan paniscus

Hominina (homininans)	
Homo sapiens (humans)

History
Main article: Human history
Prehistory
Main article: Prehistory

Overview map of the peopling of the world by early human migration during the Upper Paleolithic, following the Southern Dispersal paradigm
Until about 12,000 years ago, all humans lived as hunter-gatherers.[51][52] The Neolithic Revolution (the invention of agriculture) first took place in Southwest Asia and spread through large parts of the Old World over the following millennia.[53] It also occurred independently in Mesoamerica (about 6,000 years ago),[54] China,[55][56] Papua New Guinea,[57] and the Sahel and West Savanna regions of Africa.[58][59][60]

Access to food surplus led to the formation of permanent human settlements, the domestication of animals and the use of metal tools for the first time in history. Agriculture and sedentary lifestyle led to the emergence of early civilizations.[61][62][63]

Ancient
Main article: Ancient history

Great Pyramids of Giza, Egypt
An urban revolution took place in the 4th millennium BCE with the development of city-states, particularly Sumerian cities located in Mesopotamia.[64] It was in these cities that the earliest known form of writing, cuneiform script, appeared around 3000 BCE.[65] Other major civilizations to develop around this time were Ancient Egypt and the Indus Valley Civilisation.[66] They eventually traded with each other and invented technology such as wheels, plows and sails.[67][68][69][70] Emerging by 3000 BCE, the Caral–Supe civilization is the oldest complex civilization in the Americas.[71] Astronomy and mathematics were also developed and the Great Pyramid of Giza was built.[72][73][74] There is evidence of a severe drought lasting about a hundred years that may have caused the decline of these civilizations,[75] with new ones appearing in the aftermath. Babylonians came to dominate Mesopotamia while others,[76] such as the Poverty Point culture, Minoans and the Shang dynasty, rose to prominence in new areas.[77][78][79] The Late Bronze Age collapse around 1200 BCE resulted in the disappearance of a number of civilizations and the beginning of the Greek Dark Ages.[80][81] During this period iron started replacing bronze, leading to the Iron Age.[82]

In the 5th century BCE, history started being recorded as a discipline, which provided a much clearer picture of life at the time.[83] Between the 8th and 6th century BCE, Europe entered the classical antiquity age, a period when ancient Greece and ancient Rome flourished.[84][85] Around this time other civilizations also came to prominence. The Maya civilization started to build cities and create complex calendars.[86][87] In Africa, the Kingdom of Aksum overtook the declining Kingdom of Kush and facilitated trade between India and the Mediterranean.[88] In West Asia, the Achaemenid Empire's system of centralized governance became the precursor to many later empires,[89] while the Gupta Empire in India and the Han dynasty in China have been described as golden ages in their respective regions.[90][91]

Medieval
Main article: Post-classical history

Medieval French manuscript illustration of the three classes of medieval society from the 13th-century Li Livres dou Santé
Following the fall of the Western Roman Empire in 476, Europe entered the Middle Ages.[92] During this period, Christianity and the Church would provide centralized authority and education.[93] In the Middle East, Islam became the prominent religion and expanded into North Africa. It led to an Islamic Golden Age, inspiring achievements in architecture, the revival of old advances in science and technology, and the formation of a distinct way of life.[94][95] The Christian and Islamic worlds would eventually clash, with the Kingdom of England, the Kingdom of France and the Holy Roman Empire declaring a series of holy wars to regain control of the Holy Land from Muslims.[96]

In the Americas, between 200 and 900 CE Mesoamerica was in its Classic Period,[97] while further north, complex Mississippian societies would arise starting around 800 CE.[98] The Mongol Empire would conquer much of Eurasia in the 13th and 14th centuries.[99] Over this same time period, the Mali Empire in Africa grew to be the largest empire on the continent, stretching from Senegambia to Ivory Coast.[100] Oceania would see the rise of the Tuʻi Tonga Empire which expanded across many islands in the South Pacific.[101] By the late 15th century, the Aztecs and Inca had become the dominant power in Mesoamerica and the Andes, respectively.[102]

Modern
Main articles: Early modern period and Late modern period

James Watt's steam engine
The early modern period in Europe and the Near East (c. 1450–1800) began with the final defeat of the Byzantine Empire, and the rise of the Ottoman Empire.[103] Meanwhile, Japan entered the Edo period,[104] the Qing dynasty rose in China[105] and the Mughal Empire ruled much of India.[106] Europe underwent the Renaissance, starting in the 15th century,[107] and the Age of Discovery began with the exploring and colonizing of new regions.[108] This included the colonization of the Americas[109] and the Columbian Exchange.[110] This expansion led to the Atlantic slave trade[111] and the genocide of Native American peoples.[112] This period also marked the Scientific Revolution, with great advances in mathematics, mechanics, astronomy and physiology.[113]

The late modern period (1800–present) saw the Technological and Industrial Revolution bring such discoveries as imaging technology, major innovations in transport and energy development.[114] Influenced by Enlightenment ideals, the Americas and Europe experienced a period of political revolutions known as the Age of Revolution.[115] The Napoleonic Wars raged through Europe in the early 1800s,[116] Spain lost most of its colonies in the New World,[117] while Europeans continued expansion into Africa – where European control went from 10% to almost 90% in less than 50 years[118] – and Oceania.[119] In the 19th century, the British Empire expanded to become the world's largest empire.[120]


A laptop connected to the Internet.
A tenuous balance of power among European nations collapsed in 1914 with the outbreak of the First World War, one of the deadliest conflicts in history.[121] In the 1930s, a worldwide economic crisis led to the rise of authoritarian regimes and a Second World War, involving almost all of the world's countries.[122] The war's destruction led to the collapse of most global empires, leading to widespread decolonization.

Following the conclusion of the Second World War in 1945, the United States[123] and the USSR emerged as the remaining global superpowers. This led to a Cold War that saw a struggle for global influence, including a nuclear arms race and a space race, ending in the collapse of the Soviet Union.[124][125] The current Information Age, spurred by the development of the Internet and Artificial Intelligence systems, sees the world becoming increasingly globalized and interconnected.[126]

Habitat and population
Further information: Human geography and Demography
Population statistics[n 1]

Choropleth showing Population density (people per square kilometer) estimates by 30 arc-second grid in 2020
World population	8.1 billion
Population density	16/km2 (41/sq mi) by total area
54/km2 (141/sq mi) by land area
Largest cities[n 2]	Tokyo, Delhi, Shanghai, São Paulo, Mexico City, Cairo, Mumbai, Beijing, Dhaka, Osaka
Early human settlements were dependent on proximity to water and – depending on the lifestyle – other natural resources used for subsistence, such as populations of animal prey for hunting and arable land for growing crops and grazing livestock.[130] Modern humans, however, have a great capacity for altering their habitats by means of technology, irrigation, urban planning, construction, deforestation and desertification.[131] Human settlements continue to be vulnerable to natural disasters, especially those placed in hazardous locations and with low quality of construction.[132] Grouping and deliberate habitat alteration is often done with the goals of providing protection, accumulating comforts or material wealth, expanding the available food, improving aesthetics, increasing knowledge or enhancing the exchange of resources.[133]

Humans are one of the most adaptable species, despite having a low or narrow tolerance for many of the earth's extreme environments.[134] Currently the species is present in all eight biogeographical realms, although their presence in the Antarctic realm is very limited to research stations and annually there is a population decline in the winter months of this realm. Humans established nation-states in the other seven realms, such as South Africa, India, Russia, Australia, Fiji, United States and Brazil (each located in a different biogeographical realm).

By using advanced tools and clothing, humans have been able to extend their tolerance to a wide variety of temperatures, humidities, and altitudes.[134][135] As a result, humans are a cosmopolitan species found in almost all regions of the world, including tropical rainforest, arid desert, extremely cold arctic regions, and heavily polluted cities; in comparison, most other species are confined to a few geographical areas by their limited adaptability.[136] The human population is not, however, uniformly distributed on the Earth's surface, because the population density varies from one region to another, and large stretches of surface are almost completely uninhabited, like Antarctica and vast swathes of the ocean.[134][137] Most humans (61%) live in Asia; the remainder live in the Americas (14%), Africa (14%), Europe (11%), and Oceania (0.5%).[138]


Humans and their domesticated animals represent 96% of all mammalian biomass on earth, whereas all wild mammals represent only 4%.[139]
Estimates of the population at the time agriculture emerged in around 10,000 BC have ranged between 1 million and 15 million.[140][141] Around 50–60 million people lived in the combined eastern and western Roman Empire in the 4th century AD.[142] Bubonic plagues, first recorded in the 6th century AD, reduced the population by 50%, with the Black Death killing 75–200 million people in Eurasia and North Africa alone.[143] Human population is believed to have reached one billion in 1800. It has since then increased exponentially, reaching two billion in 1930 and three billion in 1960, four in 1975, five in 1987 and six billion in 1999.[144] It passed seven billion in 2011[145] and passed eight billion in November 2022.[146] It took over two million years of human prehistory and history for the human population to reach one billion and only 207 years more to grow to 7 billion.[147] The combined biomass of the carbon of all the humans on Earth in 2018 was estimated at 60 million tons, about 10 times larger than that of all non-domesticated mammals.[139]

In 2018, 4.2 billion humans (55%) lived in urban areas, up from 751 million in 1950.[148] The most urbanized regions are Northern America (82%), Latin America (81%), Europe (74%) and Oceania (68%), with Africa and Asia having nearly 90% of the world's 3.4 billion rural population.[148] Problems for humans living in cities include various forms of pollution and crime,[149] especially in inner city and suburban slums.

Biology
Anatomy and physiology
Main article: Human body

Basic anatomical features of female and male humans. These models have had body hair and male facial hair removed and head hair trimmed.
Most aspects of human physiology are closely homologous to corresponding aspects of animal physiology. The dental formula of humans is: 
2.1.2.3
2.1.2.3
. Humans have proportionately shorter palates and much smaller teeth than other primates. They are the only primates to have short, relatively flush canine teeth. Humans have characteristically crowded teeth, with gaps from lost teeth usually closing up quickly in young individuals. Humans are gradually losing their third molars, with some individuals having them congenitally absent.[150]

Humans share with chimpanzees a vestigial tail,[151] appendix, flexible shoulder joints, grasping fingers and opposable thumbs.[152] Humans also have a more barrel-shaped chests in contrast to the funnel shape of other apes, an adaptation for bipedal respiration.[153] Apart from bipedalism and brain size, humans differ from chimpanzees mostly in smelling, hearing and digesting proteins.[154] While humans have a density of hair follicles comparable to other apes, it is predominantly vellus hair, most of which is so short and wispy as to be practically invisible.[155][156] Humans have about 2 million sweat glands spread over their entire bodies, many more than chimpanzees, whose sweat glands are scarce and are mainly located on the palm of the hand and on the soles of the feet.[157]

It is estimated that the worldwide average height for an adult human male is about 171 cm (5 ft 7 in), while the worldwide average height for adult human females is about 159 cm (5 ft 3 in).[158] Shrinkage of stature may begin in middle age in some individuals but tends to be typical in the extremely aged.[159] Throughout history, human populations have universally become taller, probably as a consequence of better nutrition, healthcare, and living conditions.[160] The average mass of an adult human is 59 kg (130 lb) for females and 77 kg (170 lb) for males.[161][162] Like many other conditions, body weight and body type are influenced by both genetic susceptibility and environment and varies greatly among individuals.[163][164]

Humans have a far faster and more accurate throw than other animals.[165] Humans are also among the best long-distance runners in the animal kingdom, but slower over short distances.[166][154] Humans' thinner body hair and more productive sweat glands help avoid heat exhaustion while running for long distances.[167] Compared to other apes, the human heart produces greater stroke volume and cardiac output and the aorta is proportionately larger.[168][169]

Genetics
Main article: Human genetics

A graphical representation of the standard human karyotype, including both the female (XX) and male (XY) sex chromosomes.
Like most animals, humans are a diploid and eukaryotic species. Each somatic cell has two sets of 23 chromosomes, each set received from one parent; gametes have only one set of chromosomes, which is a mixture of the two parental sets. Among the 23 pairs of chromosomes, there are 22 pairs of autosomes and one pair of sex chromosomes. Like other mammals, humans have an XY sex-determination system, so that females have the sex chromosomes XX and males have XY.[170] Genes and environment influence human biological variation in visible characteristics, physiology, disease susceptibility and mental abilities. The exact influence of genes and environment on certain traits is not well understood.[171][172]

While no humans – not even monozygotic twins – are genetically identical,[173] two humans on average will have a genetic similarity of 99.5%-99.9%.[174][175] This makes them more homogeneous than other great apes, including chimpanzees.[176][177] This small variation in human DNA compared to many other species suggests a population bottleneck during the Late Pleistocene (around 100,000 years ago), in which the human population was reduced to a small number of breeding pairs.[178][179] The forces of natural selection have continued to operate on human populations, with evidence that certain regions of the genome display directional selection in the past 15,000 years.[180]

The human genome was first sequenced in 2001[181] and by 2020 hundreds of thousands of genomes had been sequenced.[182] In 2012 the International HapMap Project had compared the genomes of 1,184 individuals from 11 populations and identified 1.6 million single nucleotide polymorphisms.[183] African populations harbor the highest number of private genetic variants. While many of the common variants found in populations outside of Africa are also found on the African continent, there are still large numbers that are private to these regions, especially Oceania and the Americas.[184] By 2010 estimates, humans have approximately 22,000 genes.[185] By comparing mitochondrial DNA, which is inherited only from the mother, geneticists have concluded that the last female common ancestor whose genetic marker is found in all modern humans, the so-called mitochondrial Eve, must have lived around 90,000 to 200,000 years ago.[186][187][188][189]

Life cycle
See also: Childbirth and Life expectancy

A 10 mm human embryo at 5 weeks
Most human reproduction takes place by internal fertilization via sexual intercourse, but can also occur through assisted reproductive technology procedures.[190] The average gestation period is 38 weeks, but a normal pregnancy can vary by up to 37 days.[191] Embryonic development in the human covers the first eight weeks of development; at the beginning of the ninth week the embryo is termed a fetus.[192] Humans are able to induce early labor or perform a caesarean section if the child needs to be born earlier for medical reasons.[193] In developed countries, infants are typically 3–4 kg (7–9 lb) in weight and 47–53 cm (19–21 in) in height at birth.[194][195] However, low birth weight is common in developing countries, and contributes to the high levels of infant mortality in these regions.[196]

Compared with other species, human childbirth is dangerous, with a much higher risk of complications and death.[197] The size of the fetus's head is more closely matched to the pelvis than in other primates.[198] The reason for this is not completely understood,[n 3] but it contributes to a painful labor that can last 24 hours or more.[200] The chances of a successful labor increased significantly during the 20th century in wealthier countries with the advent of new medical technologies. In contrast, pregnancy and natural childbirth remain hazardous ordeals in developing regions of the world, with maternal death rates approximately 100 times greater than in developed countries.[201]

Both the mother and the father provide care for human offspring, in contrast to other primates, where parental care is mostly done by the mother.[202] Helpless at birth, humans continue to grow for some years, typically reaching sexual maturity at 15 to 17 years of age.[203][204][205] The human life span has been split into various stages ranging from three to twelve. Common stages include infancy, childhood, adolescence, adulthood and old age.[206] The lengths of these stages have varied across cultures and time periods but is typified by an unusually rapid growth spurt during adolescence.[207] Human females undergo menopause and become infertile at around the age of 50.[208] It has been proposed that menopause increases a woman's overall reproductive success by allowing her to invest more time and resources in her existing offspring, and in turn their children (the grandmother hypothesis), rather than by continuing to bear children into old age.[209][210]

The life span of an individual depends on two major factors, genetics and lifestyle choices.[211] For various reasons, including biological/genetic causes, women live on average about four years longer than men.[212] As of 2018, the global average life expectancy at birth of a girl is estimated to be 74.9 years compared to 70.4 for a boy.[213][214] There are significant geographical variations in human life expectancy, mostly correlated with economic development – for example, life expectancy at birth in Hong Kong is 87.6 years for girls and 81.8 for boys, while in the Central African Republic, it is 55.0 years for girls and 50.6 for boys.[215][216] The developed world is generally aging, with the median age around 40 years. In the developing world, the median age is between 15 and 20 years. While one in five Europeans is 60 years of age or older, only one in twenty Africans is 60 years of age or older.[217] In 2012, the United Nations estimated that there were 316,600 living centenarians (humans of age 100 or older) worldwide.[218]

Human life stages










Infant boy and girl	Boy and girl before puberty (children)	Adolescent male and female	Adult man and woman	Elderly man and woman
Diet
Main article: Human nutrition

Humans living in Bali, Indonesia, preparing a meal
Humans are omnivorous,[219] capable of consuming a wide variety of plant and animal material.[220][221] Human groups have adopted a range of diets from purely vegan to primarily carnivorous. In some cases, dietary restrictions in humans can lead to deficiency diseases; however, stable human groups have adapted to many dietary patterns through both genetic specialization and cultural conventions to use nutritionally balanced food sources.[222] The human diet is prominently reflected in human culture and has led to the development of food science.[223]

Until the development of agriculture, Homo sapiens employed a hunter-gatherer method as their sole means of food collection.[223] This involved combining stationary food sources (such as fruits, grains, tubers, and mushrooms, insect larvae and aquatic mollusks) with wild game, which must be hunted and captured in order to be consumed.[224] It has been proposed that humans have used fire to prepare and cook food since the time of Homo erectus.[225] Human domestication of wild plants began about 11,700 years ago, leading to the development of agriculture,[226] a gradual process called the Neolithic Revolution.[227] These dietary changes may also have altered human biology; the spread of dairy farming provided a new and rich source of food, leading to the evolution of the ability to digest lactose in some adults.[228][229] The types of food consumed, and how they are prepared, have varied widely by time, location, and culture.[230][231]

In general, humans can survive for up to eight weeks without food, depending on stored body fat.[232] Survival without water is usually limited to three or four days, with a maximum of one week.[233] In 2020 it is estimated 9 million humans die every year from causes directly or indirectly related to starvation.[234][235] Childhood malnutrition is also common and contributes to the global burden of disease.[236] However, global food distribution is not even, and obesity among some human populations has increased rapidly, leading to health complications and increased mortality in some developed and a few developing countries. Worldwide, over one billion people are obese,[237] while in the United States 35% of people are obese, leading to this being described as an "obesity epidemic."[238] Obesity is caused by consuming more calories than are expended, so excessive weight gain is usually caused by an energy-dense diet.[237]

Biological variation
Main article: Human genetic variation

A Libyan, a Nubian, a Syrian, and an Egyptian, drawing by an unknown artist after a mural of the tomb of Seti I
There is biological variation in the human species – with traits such as blood type, genetic diseases, cranial features, facial features, organ systems, eye color, hair color and texture, height and build, and skin color varying across the globe. The typical height of an adult human is between 1.4 and 1.9 m (4 ft 7 in and 6 ft 3 in), although this varies significantly depending on sex, ethnic origin, and family bloodlines.[239][240] Body size is partly determined by genes and is also significantly influenced by environmental factors such as diet, exercise, and sleep patterns.[241]


A variety of human hair colors; from top left, clockwise: black, brown, blonde, white, red.
There is evidence that populations have adapted genetically to various external factors. The genes that allow adult humans to digest lactose are present in high frequencies in populations that have long histories of cattle domestication and are more dependent on cow milk.[242] Sickle cell anemia, which may provide increased resistance to malaria, is frequent in populations where malaria is endemic.[243][244] Populations that have for a very long time inhabited specific climates tend to have developed specific phenotypes that are beneficial for those environments – short stature and stocky build in cold regions, tall and lanky in hot regions, and with high lung capacities or other adaptations at high altitudes.[245] Some populations have evolved highly unique adaptations to very specific environmental conditions, such as those advantageous to ocean-dwelling lifestyles and freediving in the Bajau.[246]

Human hair ranges in color from red to blond to brown to black, which is the most frequent.[247] Hair color depends on the amount of melanin, with concentrations fading with increased age, leading to grey or even white hair. Skin color can range from darkest brown to lightest peach, or even nearly white or colorless in cases of albinism.[248] It tends to vary clinally and generally correlates with the level of ultraviolet radiation in a particular geographic area, with darker skin mostly around the equator.[249] Skin darkening may have evolved as protection against ultraviolet solar radiation.[250] Light skin pigmentation protects against depletion of vitamin D, which requires sunlight to make.[251] Human skin also has a capacity to darken (tan) in response to exposure to ultraviolet radiation.[252][253]

There is relatively little variation between human geographical populations, and most of the variation that occurs is at the individual level.[248][254][255] Much of human variation is continuous, often with no clear points of demarcation.[256][257][258][259] Genetic data shows that no matter how population groups are defined, two people from the same population group are almost as different from each other as two people from any two different population groups.[260][261][262] Dark-skinned populations that are found in Africa, Australia, and South Asia are not closely related to each other.[263][264]

Genetic research has demonstrated that human populations native to the African continent are the most genetically diverse[265] and genetic diversity decreases with migratory distance from Africa, possibly the result of bottlenecks during human migration.[266][267] These non-African populations acquired new genetic inputs from local admixture with archaic populations and have much greater variation from Neanderthals and Denisovans than is found in Africa,[184] though Neanderthal admixture into African populations may be underestimated.[268] Furthermore, recent studies have found that populations in sub-Saharan Africa, and particularly West Africa, have ancestral genetic variation which predates modern humans and has been lost in most non-African populations. Some of this ancestry is thought to originate from admixture with an unknown archaic hominin that diverged before the split of Neanderthals and modern humans.[269][270]

Humans are a gonochoric species, meaning they are divided into male and female sexes.[271][272][273] The greatest degree of genetic variation exists between males and females. While the nucleotide genetic variation of individuals of the same sex across global populations is no greater than 0.1%–0.5%, the genetic difference between males and females is between 1% and 2%. Males on average are 15% heavier and 15 cm (6 in) taller than females.[274][275] On average, men have about 40–50% more upper-body strength and 20–30% more lower-body strength than women at the same weight, due to higher amounts of muscle and larger muscle fibers.[276] Women generally have a higher body fat percentage than men.[277] Women have lighter skin than men of the same population; this has been explained by a higher need for vitamin D in females during pregnancy and lactation.[278] As there are chromosomal differences between females and males, some X and Y chromosome-related conditions and disorders only affect either men or women.[279] After allowing for body weight and volume, the male voice is usually an octave deeper than the female voice.[280] Women have a longer life span in almost every population around the world.[281] There are intersex conditions in the human population, however these are rare.[282][283]

Psychology
Main article: Psychology

Drawing of the human brain, showing several important structures
The human brain, the focal point of the central nervous system in humans, controls the peripheral nervous system. In addition to controlling "lower", involuntary, or primarily autonomic activities such as respiration and digestion, it is also the locus of "higher" order functioning such as thought, reasoning, and abstraction.[284] These cognitive processes constitute the mind, and, along with their behavioral consequences, are studied in the field of psychology.

Humans have a larger and more developed prefrontal cortex than other primates, the region of the brain associated with higher cognition.[285][286] This has led humans to proclaim themselves to be more intelligent than any other known species.[287] Objectively defining intelligence is difficult, with other animals adapting senses and excelling in areas that humans are unable to.[288]

There are some traits that, although not strictly unique, do set humans apart from other animals.[289] Humans may be the only animals who have episodic memory and who can engage in "mental time travel".[290] Even compared with other social animals, humans have an unusually high degree of flexibility in their facial expressions.[291] Humans are the only animals known to cry emotional tears.[292] Humans are one of the few animals able to self-recognize in mirror tests[293] and there is also debate over to what extent humans are the only animals with a theory of mind.[294][295]

Sleep and dreaming
Main articles: Sleep and Dream
Humans are generally diurnal. The average sleep requirement is between seven and nine hours per day for an adult and nine to ten hours per day for a child; elderly people usually sleep for six to seven hours. Having less sleep than this is common among humans, even though sleep deprivation can have negative health effects. A sustained restriction of adult sleep to four hours per day has been shown to correlate with changes in physiology and mental state, including reduced memory, fatigue, aggression, and bodily discomfort.[296]

During sleep humans dream, where they experience sensory images and sounds. Dreaming is stimulated by the pons and mostly occurs during the REM phase of sleep.[297] The length of a dream can vary, from a few seconds up to 30 minutes.[298] Humans have three to five dreams per night, and some may have up to seven.[299] Dreamers are more likely to remember the dream if awakened during the REM phase. The events in dreams are generally outside the control of the dreamer, with the exception of lucid dreaming, where the dreamer is self-aware.[300] Dreams can at times make a creative thought occur or give a sense of inspiration.[301]

Consciousness and thought
Main articles: Consciousness and Cognition
Human consciousness, at its simplest, is sentience or awareness of internal or external existence.[302] Despite centuries of analyses, definitions, explanations and debates by philosophers and scientists, consciousness remains puzzling and controversial,[303] being "at once the most familiar and most mysterious aspect of our lives".[304] The only widely agreed notion about the topic is the intuition that it exists.[305] Opinions differ about what exactly needs to be studied and explained as consciousness. Some philosophers divide consciousness into phenomenal consciousness, which is sensory experience itself, and access consciousness, which can be used for reasoning or directly controlling actions.[306] It is sometimes synonymous with 'the mind', and at other times, an aspect of it. Historically it is associated with introspection, private thought, imagination and volition.[307] It now often includes some kind of experience, cognition, feeling or perception. It may be 'awareness', or 'awareness of awareness', or self-awareness.[308] There might be different levels or orders of consciousness,[309] or different kinds of consciousness, or just one kind with different features.[310]

The process of acquiring knowledge and understanding through thought, experience, and the senses is known as cognition.[311] The human brain perceives the external world through the senses, and each individual human is influenced greatly by his or her experiences, leading to subjective views of existence and the passage of time.[312] The nature of thought is central to psychology and related fields. Cognitive psychology studies cognition, the mental processes underlying behavior.[313] Largely focusing on the development of the human mind through the life span, developmental psychology seeks to understand how people come to perceive, understand, and act within the world and how these processes change as they age.[314][315] This may focus on intellectual, cognitive, neural, social, or moral development. Psychologists have developed intelligence tests and the concept of intelligence quotient in order to assess the relative intelligence of human beings and study its distribution among population.[316]

Motivation and emotion
Main articles: Motivation and Emotion

Illustration of grief from Charles Darwin's 1872 book The Expression of the Emotions in Man and Animals
Human motivation is not yet wholly understood. From a psychological perspective, Maslow's hierarchy of needs is a well-established theory that can be defined as the process of satisfying certain needs in ascending order of complexity.[317] From a more general, philosophical perspective, human motivation can be defined as a commitment to, or withdrawal from, various goals requiring the application of human ability. Furthermore, incentive and preference are both factors, as are any perceived links between incentives and preferences. Volition may also be involved, in which case willpower is also a factor. Ideally, both motivation and volition ensure the selection, striving for, and realization of goals in an optimal manner, a function beginning in childhood and continuing throughout a lifetime in a process known as socialization.[318]

Emotions are biological states associated with the nervous system[319][320] brought on by neurophysiological changes variously associated with thoughts, feelings, behavioral responses, and a degree of pleasure or displeasure.[321][322] They are often intertwined with mood, temperament, personality, disposition, creativity,[323] and motivation. Emotion has a significant influence on human behavior and their ability to learn.[324] Acting on extreme or uncontrolled emotions can lead to social disorder and crime,[325] with studies showing criminals may have a lower emotional intelligence than normal.[326]

Emotional experiences perceived as pleasant, such as joy, interest or contentment, contrast with those perceived as unpleasant, like anxiety, sadness, anger, and despair.[327] Happiness, or the state of being happy, is a human emotional condition. The definition of happiness is a common philosophical topic. Some define it as experiencing the feeling of positive emotional affects, while avoiding the negative ones.[328][329] Others see it as an appraisal of life satisfaction or quality of life.[330] Recent research suggests that being happy might involve experiencing some negative emotions when humans feel they are warranted.[331]

Sexuality and love
Main articles: Human sexuality and Love

Human parents often display familial love for their children.
For humans, sexuality involves biological, erotic, physical, emotional, social, or spiritual feelings and behaviors.[332][333] Because it is a broad term, which has varied with historical contexts over time, it lacks a precise definition.[333] The biological and physical aspects of sexuality largely concern the human reproductive functions, including the human sexual response cycle.[332][333] Sexuality also affects and is affected by cultural, political, legal, philosophical, moral, ethical, and religious aspects of life.[332][333] Sexual desire, or libido, is a basic mental state present at the beginning of sexual behavior. Studies show that men desire sex more than women and masturbate more often.[334]

Humans can fall anywhere along a continuous scale of sexual orientation,[335] although most humans are heterosexual.[336][337] While homosexual behavior occurs in some other animals, only humans and domestic sheep have so far been found to exhibit exclusive preference for same-sex relationships.[336] Most evidence supports nonsocial, biological causes of sexual orientation,[336] as cultures that are very tolerant of homosexuality do not have significantly higher rates of it.[337][338] Research in neuroscience and genetics suggests that other aspects of human sexuality are biologically influenced as well.[339]

Love most commonly refers to a feeling of strong attraction or emotional attachment. It can be impersonal (the love of an object, ideal, or strong political or spiritual connection) or interpersonal (love between humans).[340] When in love dopamine, norepinephrine, serotonin and other chemicals stimulate the brain's pleasure center, leading to side effects such as increased heart rate, loss of appetite and sleep, and an intense feeling of excitement.[341]

Culture
Main articles: Culture and Cultural universal
Human society statistics
Most widely spoken languages[342][343]	English, Mandarin Chinese, Hindi, Spanish, Standard Arabic, Bengali, French, Russian, Portuguese, Urdu
Most practiced religions[343][344]	Christianity, Islam, Hinduism, Buddhism, folk religions, Sikhism, Judaism, unaffiliated
Humanity's unprecedented set of intellectual skills were a key factor in the species' eventual technological advancement and concomitant domination of the biosphere.[345] Disregarding extinct hominids, humans are the only animals known to teach generalizable information,[346] innately deploy recursive embedding to generate and communicate complex concepts,[347] engage in the "folk physics" required for competent tool design,[348][349] or cook food in the wild.[350] Teaching and learning preserves the cultural and ethnographic identity of human societies.[351] Other traits and behaviors that are mostly unique to humans include starting fires,[352] phoneme structuring[353] and vocal learning.[354]

Language
Main article: Language

Principal language families of the world (and in some cases geographic groups of families). For greater detail, see Distribution of languages in the world.
While many species communicate, language is unique to humans, a defining feature of humanity, and a cultural universal.[355] Unlike the limited systems of other animals, human language is open – an infinite number of meanings can be produced by combining a limited number of symbols.[356][357] Human language also has the capacity of displacement, using words to represent things and happenings that are not presently or locally occurring but reside in the shared imagination of interlocutors.[150]

Language differs from other forms of communication in that it is modality independent; the same meanings can be conveyed through different media, audibly in speech, visually by sign language or writing, and through tactile media such as braille.[358] Language is central to the communication between humans, and to the sense of identity that unites nations, cultures and ethnic groups.[359] There are approximately six thousand different languages currently in use, including sign languages, and many thousands more that are extinct.[360]

The arts
Main article: The arts
Human arts can take many forms including visual, literary, and performing. Visual art can range from paintings and sculptures to film, fashion design, and architecture.[361] Literary arts can include prose, poetry, and dramas. The performing arts generally involve theatre, music, and dance.[362][363] Humans often combine the different forms (for example, music videos).[364] Other entities that have been described as having artistic qualities include food preparation, video games, and medicine.[365][366][367] As well as providing entertainment and transferring knowledge, the arts are also used for political purposes.[368]


The Deluge tablet of the Gilgamesh epic in Akkadian
Art is a defining characteristic of humans and there is evidence for a relationship between creativity and language.[369] The earliest evidence of art was shell engravings made by Homo erectus 300,000 years before modern humans evolved.[370] Art attributed to H. sapiens existed at least 75,000 years ago, with jewellery and drawings found in caves in South Africa.[371][372] There are various hypotheses as to why humans have adapted to the arts. These include allowing them to better problem solve issues, providing a means to control or influence other humans, encouraging cooperation and contribution within a society or increasing the chance of attracting a potential mate.[373] The use of imagination developed through art, combined with logic may have given early humans an evolutionary advantage.[369]

Evidence of humans engaging in musical activities predates cave art and so far music has been practiced by virtually all known human cultures.[374] There exists a wide variety of music genres and ethnic musics; with humans' musical abilities being related to other abilities, including complex social human behaviours.[374] It has been shown that human brains respond to music by becoming synchronized with the rhythm and beat, a process called entrainment.[375] Dance is also a form of human expression found in all cultures[376] and may have evolved as a way to help early humans communicate.[377] Listening to music and observing dance stimulates the orbitofrontal cortex and other pleasure sensing areas of the brain.[378]

Unlike speaking, reading and writing does not come naturally to humans and must be taught.[379] Still, literature has been present before the invention of words and language, with 30,000-year-old paintings on walls inside some caves portraying a series of dramatic scenes.[380] One of the oldest surviving works of literature is the Epic of Gilgamesh, first engraved on ancient Babylonian tablets about 4,000 years ago.[381] Beyond simply passing down knowledge, the use and sharing of imaginative fiction through stories might have helped develop humans' capabilities for communication and increased the likelihood of securing a mate.[382] Storytelling may also be used as a way to provide the audience with moral lessons and encourage cooperation.[380]

Tools and technologies
Main articles: Tool and Technology
Train running on a track
The SCMaglev, the fastest train in the world clocking in at 603 km/h (375 mph) as of 2015[383]
Stone tools were used by proto-humans at least 2.5 million years ago.[384] The use and manufacture of tools has been put forward as the ability that defines humans more than anything else[385] and has historically been seen as an important evolutionary step.[386] The technology became much more sophisticated about 1.8 million years ago,[385] with the controlled use of fire beginning around 1 million years ago.[387][388] The wheel and wheeled vehicles appeared simultaneously in several regions some time in the fourth millennium BC.[68] The development of more complex tools and technologies allowed land to be cultivated and animals to be domesticated, thus proving essential in the development of agriculture – what is known as the Neolithic Revolution.[389]

China developed paper, the printing press, gunpowder, the compass and other important inventions.[390] The continued improvements in smelting allowed forging of copper, bronze, iron and eventually steel, which is used in railways, skyscrapers and many other products.[391] This coincided with the Industrial Revolution, where the invention of automated machines brought major changes to humans' lifestyles.[392] Modern technology is observed as progressing exponentially,[393] with major innovations in the 20th century including: electricity, penicillin, semiconductors, internal combustion engines, the Internet, nitrogen fixing fertilizers, airplanes, computers, automobiles, contraceptive pills, nuclear fission, the green revolution, radio, scientific plant breeding, rockets, air conditioning, television and the assembly line.[394]

Religion and spirituality
Main articles: Religion and Spirituality

Shango, the Orisha of fire, lightning, and thunder, in the Yoruba religion, depicted on horseback
Definitions of religion vary;[395] according to one definition, a religion is a belief system concerning the supernatural, sacred or divine, and practices, values, institutions and rituals associated with such belief. Some religions also have a moral code. The evolution and the history of the first religions have become areas of active scientific investigation.[396][397][398] Credible evidence of religious behaviour dates to the Middle Paleolithic era (45–200 thousand years ago).[399] It may have evolved to play a role in helping enforce and encourage cooperation between humans.[400]

Religion manifests in diverse forms.[395] Religion can include a belief in life after death,[401] the origin of life, the nature of the universe (religious cosmology) and its ultimate fate (eschatology), and moral or ethical teachings.[402] Views on transcendence and immanence vary substantially; traditions variously espouse monism, deism, pantheism, and theism (including polytheism and monotheism).[403]

Although measuring religiosity is difficult,[404] a majority of humans profess some variety of religious or spiritual belief.[405] In 2015 the plurality were Christian followed by Muslims, Hindus and Buddhists.[406] As of 2015, about 16%, or slightly under 1.2 billion humans, were irreligious, including those with no religious beliefs or no identity with any religion.[407]

Science and philosophy
Main articles: Science and Philosophy

The Dunhuang map, a star map showing the North Polar region. China circa 700.
An aspect unique to humans is their ability to transmit knowledge from one generation to the next and to continually build on this information to develop tools, scientific laws and other advances to pass on further.[408] This accumulated knowledge can be tested to answer questions or make predictions about how the universe functions and has been very successful in advancing human ascendancy.[409]

Aristotle has been described as the first scientist,[410] and preceded the rise of scientific thought through the Hellenistic period.[411] Other early advances in science came from the Han dynasty in China and during the Islamic Golden Age.[412][94] The scientific revolution, near the end of the Renaissance, led to the emergence of modern science.[413]

A chain of events and influences led to the development of the scientific method, a process of observation and experimentation that is used to differentiate science from pseudoscience.[414] An understanding of mathematics is unique to humans, although other species of animals have some numerical cognition.[415] All of science can be divided into three major branches, the formal sciences (e.g., logic and mathematics), which are concerned with formal systems, the applied sciences (e.g., engineering, medicine), which are focused on practical applications, and the empirical sciences, which are based on empirical observation and are in turn divided into natural sciences (e.g., physics, chemistry, biology) and social sciences (e.g., psychology, economics, sociology).[416]

Philosophy is a field of study where humans seek to understand fundamental truths about themselves and the world in which they live.[417] Philosophical inquiry has been a major feature in the development of humans' intellectual history.[418] It has been described as the "no man's land" between definitive scientific knowledge and dogmatic religious teachings.[419] Major fields of philosophy include metaphysics, epistemology, logic, and axiology (which includes ethics and aesthetics).[420]

Society
Main article: Society

Humans often live in family-based social structures
Society is the system of organizations and institutions arising from interaction between humans. Humans are highly social and tend to live in large complex social groups. They can be divided into different groups according to their income, wealth, power, reputation and other factors. The structure of social stratification and the degree of social mobility differs, especially between modern and traditional societies.[421] Human groups range from the size of families to nations. The first form of human social organization is thought to have resembled hunter-gatherer band societies.[422]

Gender
Main article: Gender

Depiction of a man and a woman from the Pioneer plaque
Human societies typically exhibit gender identities and gender roles that distinguish between masculine and feminine characteristics and prescribe the range of acceptable behaviours and attitudes for their members based on their sex.[423][424] The most common categorisation is a gender binary of men and women.[425] Some societies recognize a third gender,[426] or less commonly a fourth or fifth.[427][428] In some other societies, non-binary is used as an umbrella term for a range of gender identities that are not solely male or female.[429]

Gender roles are often associated with a division of norms, practices, dress, behavior, rights, duties, privileges, status, and power, with men enjoying more rights and privileges than women in most societies, both today and in the past.[430] As a social construct,[431] gender roles are not fixed and vary historically within a society. Challenges to predominant gender norms have recurred in many societies.[432][433] Little is known about gender roles in the earliest human societies. Early modern humans probably had a range of gender roles similar to that of modern cultures from at least the Upper Paleolithic, while the Neanderthals were less sexually dimorphic and there is evidence that the behavioural difference between males and females was minimal.[434]

Kinship
Main article: Kinship
All human societies organize, recognize and classify types of social relationships based on relations between parents, children and other descendants (consanguinity), and relations through marriage (affinity). There is also a third type applied to godparents or adoptive children (fictive). These culturally defined relationships are referred to as kinship. In many societies, it is one of the most important social organizing principles and plays a role in transmitting status and inheritance.[435] All societies have rules of incest taboo, according to which marriage between certain kinds of kin relations is prohibited, and some also have rules of preferential marriage with certain kin relations.[436]

Pair bonding is a ubiquitous feature of human sexual relationships, whether it is manifested as serial monogamy, polygyny, or polyandry.[437] Genetic evidence indicates that humans were predominantly polygynous for most of their existence as a species, but that this began to shift during the Neolithic, when monogamy started becoming widespread concomitantly with the transition from nomadic to sedentary societies.[438] Anatomical evidence in the form of second-to-fourth digit ratios, a biomarker for prenatal androgen effects, likewise indicates modern humans were polygynous during the Pleistocene.[439]

Ethnicity
Main article: Ethnic group
Human ethnic groups are a social category that identifies together as a group based on shared attributes that distinguish them from other groups. These can be a common set of traditions, ancestry, language, history, society, culture, nation, religion, or social treatment within their residing area.[440][441] Ethnicity is separate from the concept of race, which is based on physical characteristics, although both are socially constructed.[442] Assigning ethnicity to a certain population is complicated, as even within common ethnic designations there can be a diverse range of subgroups, and the makeup of these ethnic groups can change over time at both the collective and individual level.[176] Also, there is no generally accepted definition of what constitutes an ethnic group.[443] Ethnic groupings can play a powerful role in the social identity and solidarity of ethnopolitical units. This has been closely tied to the rise of the nation state as the predominant form of political organization in the 19th and 20th centuries.[444][445][446]

Government and politics
Main articles: Government and Politics

The United Nations headquarters (left) in New York City, which houses one of the world's largest political organizations
As farming populations gathered in larger and denser communities, interactions between these different groups increased. This led to the development of governance within and between the communities.[447] Humans have evolved the ability to change affiliation with various social groups relatively easily, including previously strong political alliances, if doing so is seen as providing personal advantages.[448] This cognitive flexibility allows individual humans to change their political ideologies, with those with higher flexibility less likely to support authoritarian and nationalistic stances.[449]

Governments create laws and policies that affect the citizens that they govern. There have been many forms of government throughout human history, each having various means of obtaining power and the ability to exert diverse controls on the population.[450] Approximately 47% of humans live in some form of a democracy, 17% in a hybrid regime, and 37% in an authoritarian regime.[451] Many countries belong to international organizations and alliances; the largest of these is the United Nations, with 193 member states.[452]

Trade and economics
Main articles: Trade and Economics

The Silk Road (red) and spice trade routes (blue)
Trade, the voluntary exchange of goods and services, is seen as a characteristic that differentiates humans from other animals and has been cited as a practice that gave Homo sapiens a major advantage over other hominids.[453] Evidence suggests early H. sapiens made use of long-distance trade routes to exchange goods and ideas, leading to cultural explosions and providing additional food sources when hunting was sparse, while such trade networks did not exist for the now extinct Neanderthals.[454][455] Early trade likely involved materials for creating tools like obsidian.[456] The first truly international trade routes were around the spice trade through the Roman and medieval periods.[457]

Early human economies were more likely to be based around gift giving instead of a bartering system.[458] Early money consisted of commodities; the oldest being in the form of cattle and the most widely used being cowrie shells.[459] Money has since evolved into governmental issued coins, paper and electronic money.[459] Human study of economics is a social science that looks at how societies distribute scarce resources among different people.[460] There are massive inequalities in the division of wealth among humans; the eight richest humans are worth the same monetary value as the poorest half of all the human population.[461]

Conflict
Main article: Conflict (process)

American troops landing at Normandy, WWII.
Humans commit violence on other humans at a rate comparable to other primates, but have an increased preference for killing adults, infanticide being more common among other primates.[462] Phylogenetic analysis predicts that 2% of early H. sapiens would be murdered, rising to 12% during the medieval period, before dropping to below 2% in modern times.[463] There is great variation in violence between human populations, with rates of homicide about 0.01% in societies that have legal systems and strong cultural attitudes against violence.[464]

The willingness of humans to kill other members of their species en masse through organized conflict (i.e., war) has long been the subject of debate. One school of thought holds that war evolved as a means to eliminate competitors, and has always been an innate human characteristic. Another suggests that war is a relatively recent phenomenon and has appeared due to changing social conditions.[465] While not settled, current evidence indicates warlike predispositions only became common about 10,000 years ago, and in many places much more recently than that.[465] War has had a high cost on human life; it is estimated that during the 20th century, between 167 million and 188 million people died as a result of war.[466] War casualty data is less reliable for pre-medieval times, especially global figures. But compared with any period over the past 600 years, the last ~80 years (post 1946), has seen a very significant drop in global military and civilian death rates due to armed conflict.
The contemporary national legal systems are generally based on one of four major legal traditions: civil law, common law, customary law, religious law or combinations of these. However, the legal system of each country is shaped by its unique history and so incorporates individual variations.[1] The science that studies law at the level of legal systems is called comparative law.

Both civil (also known as Roman) and common law systems can be considered the most widespread in the world: civil law because it is the most widespread by landmass and by population overall, and common law because it is employed by the greatest number of people compared to any single civil law system.[2][3][4]

Civil law
Main article: Civil law (legal system)

Emperor Justinian I, author of what became the foundational texts of the civil law tradition.
The source of law that is recognized as authoritative is codifications in a constitution or statute passed by legislature, to amend a code. While the concept of codification dates back to the Code of Hammurabi in Babylon ca. 1790 BC, civil law systems derive from the Roman Empire and, more particularly, the Corpus Juris Civilis issued by the Emperor Justinian ca. AD 529. This was an extensive reform of the law in the Byzantine Empire, bringing it together into codified documents. Civil law was also partly influenced by religious laws such as Canon law and Islamic law.[5][6] Civil law today, in theory, is interpreted rather than developed or made by judges. Only legislative enactments (rather than legal precedents, as in common law) are considered legally binding.

Scholars of comparative law and economists promoting the legal origins theory usually subdivide civil law into distinct groups:

French civil law: in France, the Benelux countries, Italy, Romania, Spain and former colonies of those countries, mainly in Latin America, Africa and the Middle East;
German civil law: in Germany, Austria, Russia, Switzerland, Estonia, Latvia, Bosnia and Herzegovina, Croatia, Kosovo*, North Macedonia, Montenegro, Slovenia, Serbia, Greece, Portugal and its former colonies, Turkey, and East Asian countries including Japan, South Korea, and Taiwan (Republic of China);
Scandinavian civil law: in Northern Europe such as Denmark, Norway, Finland, Iceland and Sweden. As historically integrated into the Scandinavian cultural sphere, Finland and Iceland also inherited the system, although especially Iceland has its own legal roots. Scandinavian or Nordic civil law exhibit least similar treats with other civil law systems and is sometimes considered a legal system in its own right, despite reception from mainly German civil law.
However, some of these legal systems are often and more correctly said to be of hybrid nature:

Napoleonic to Germanistic influence (Italian civil law)
The Italian civil code of 1942 replaced the original one of 1865, introducing germanistic elements due to the geopolitical alliances of the time.[7] The Italian approach has been imitated by other countries including Portugal (1966), the Netherlands (1992), Lithuania (2000), Brazil (2002) and Argentina (2014). Most of them have innovations introduced by the Italian legislation, including the unification of the civil and commercial codes.[8]

Germanistic to Napoleonic influence (Swiss civil law)
The Swiss civil code is considered mainly influenced by the German civil code and partly influenced by the French civil code. The civil code of the Republic of Turkey is a slightly modified version of the Swiss code, adopted in 1926 during Mustafa Kemal Atatürk's presidency as part of the government's progressive reforms and secularization.
The Napoleonic Code (French: Code Napoléon), officially the Civil Code of the French (French: Code civil des Français; simply referred to as Code civil), is the French civil code established during the French Consulate in 1804 and still in force in France, although heavily and frequently amended since its inception.[1] Although Napoleon himself was not directly involved in the drafting of the Code, as it was drafted by a commission of four eminent jurists,[2] he chaired many of the commission's plenary sessions,[3] and his support was crucial to its passage into law.[4]

The code, with its stress on clearly written and accessible law, was a major milestone in the abolition of the previous patchwork of feudal laws.[5] Historian Robert Holtman regards it as one of the few documents that have influenced the whole world.[2] The Napoleonic Code is often portrayed to be one of the most widespread systems of law in the world, claimed to be in force in various forms in about 120 countries, but many of those countries are civil code countries that had their own version of their civil code for centuries.[6]

The Napoleonic Code was not the first legal code to be established in a European country with a civil-law legal system; it was preceded by the Codex Maximilianeus bavaricus civilis (Bavaria, 1756), the Allgemeines Landrecht (Prussia, 1794), and the West Galician Code (Galicia, then part of Austria, 1797).[citation needed] It was, however, the first modern legal code to be adopted with a pan-European scope, and it strongly influenced the law of many of the countries formed during and after the Napoleonic Wars.[7][2] The Napoleonic Code influenced developing countries outside Europe attempting to modernise and defeudalise their countries through legal reforms, such as those in the Middle East,[8] while in Latin America the Spanish and Portuguese had established their own versions of the civil code.[9]


The Napoleonic Code in the Historical Museum of the Palatinate in Speyer
History
The categories of the Napoleonic Code were not drawn from earlier French law, but instead from Justinian's sixth-century codification of Roman law, the Corpus Juris Civilis, and within it, the Institutes.[10] The Institutes divide into the law of:

persons
things
actions.
Similarly, the Napoleonic Code divided the law into four sections:

persons
property
acquisition of property
civil procedure (moved into a separate code in 1806).
Prior codification attempts
Before the Napoleonic Code, France did not have a single set of laws; law consisted mainly of local customs, sometimes officially compiled in "custumals" (coutumes), notably the Custom of Paris. There were also exemptions, privileges, and special charters granted by kings or other feudal lords. With the Revolution, the last vestiges of feudalism were abolished.[citation needed]

Specifically, as to civil law, the many different bodies of law used in different parts of France were to be replaced by a single legal code. The Constituent Assembly on 5 October 1790 voted for a codification of French laws, the Constitution of 1791 promised one, and the National Assembly adopted a unanimous resolution on 4 September 1791 providing that "there shall be a code of civil laws common for the entire realm."[11] However, it was the National Convention in 1793 which established a special commission headed by Jean-Jacques-Régis de Cambacérès to oversee the drafting process.[12]

His drafts of 1793 (for which Cambacérès had been given a one month deadline), 1794, and 1796 were all rejected by a National Convention and the French Directory of the time was more preoccupied with the turmoil resulting from various wars and strife with other European powers. The first draft contained 719 articles and was very revolutionary, but was rejected for being too technical and criticised for not being radical or philosophical enough. The second, with only 297 articles, was rejected for being too brief and was criticised for being a mere manual of morals. The third, expanded to 1,104 articles, was presented under the conservative Directory regime, but never even came up for discussion.[citation needed]

Another commission, established in December 1799 established a fourth outline drafted in part by Jean-Ignace Jacqueminot [fr] (1754–1813). Jacqueminot's draft, the so-called loi Jacqueminot, dealt almost exclusively with persons[13] and emphasised the need to reform the divorce laws, to strengthen parental authority and increase the testator's freedom to dispose of the free portion of his estate.[14] It was rejected.

Napoleonic reforms

This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (March 2011) (Learn how and when to remove this message)
Napoleon's victory at the Battle of Marengo allowed him to consolidate his power in France[15] Returning to Paris, he appointed on 12 August 1800 a commission of distinguished jurists and politicians, including fr:Jacques de Maleville, François Denis Tronchet, Félix-Julien-Jean Bigot de Préameneu, Jean-Étienne-Marie Portalis to draft a civil code.[16] For this commission, Cambacérès (now Second Consul), and Napoleon himself chaired the plenary sessions.[3] After this process finished, the Code was sent to the Legislative Body as a preliminary bill in December 1801, where it was rejected by a vote of 142 to 139.[17] In response, Napoleon announced on 2 January 1802 that he was suspending all projects, effectively closing the assemblies' sessions; simultaneously, he went to the Sénat conservateur to berate its members. These tactics cowed the legislature into submission, and gave Napoleon the majority he needed.[18] The code finally came into effect on 21 March 1804.[19]

The process developed mainly out of the various customs,[clarification needed] but was inspired by Justinian's sixth-century codification of Roman law, the Corpus Juris Civilis and, within that, Justinian's Code (Codex). The Napoleonic Code, however, differed from Justinian's in important ways:

it incorporated all kinds of earlier rules, not just legislation;
it was not a collection of edited extracts, but a comprehensive rewrite;
its structure was much more rational;
it had no religious content
it was written in the vernacular.
The Napoleonic Code marked a fundamental change in the nature of the civil law legal system, making laws clearer and more accessible. It also superseded the former conflict between royal legislative power and, particularly in the final years before the Revolution, protests by judges representing views and privileges of the social classes to which they belonged. Such conflict led the Revolutionaries to take a negative view of judges making law.

This is reflected in the Napoleonic Code provision prohibiting judges from deciding a case by way of introducing a general rule (Article 5), since the creation of general rules is an exercise of legislative and not of judicial power. In theory, there is thus no case law in France. However, the courts still had to fill in the gaps in the laws and regulations and, indeed, were prohibited from refusing to do so (Article 4). Moreover, both the code and legislation have required judicial interpretation. Thus a vast body of case law has come into existence, but without any rule of stare decisis.[citation needed]

Contents of the Napoleonic Code
The preliminary article of the code established certain important provisions regarding the rule of law. Laws could be applied only if they had been duly promulgated, and then only if they had previously been officially published (including provisions for publishing delays, given the means of communication available at the time). In brief, no secret laws were authorised. It prohibited ex post facto laws (i.e. laws that apply to events that occurred before their introduction). The code also prohibited judges from refusing to do justice on grounds of the insufficiency of the law, thereby encouraging them to interpret the law. On the other hand, it also prohibited judges from making general judgements of a legislative nature (see above).[20][unreliable source?]

With regard to family, the code established the supremacy of the husband over his wife and children, the status quo in Europe at the time. Women had even fewer rights than children. Divorce by mutual consent was abolished in 1804.[21]

Other French Napoleonic-era codes
The draft Military Code was presented to Napoleon by the special commission headed by Pierre Daru in June 1805; however, as the War of the Third Coalition progressed, the code was put aside and never implemented.

In 1791, Louis Michel le Peletier de Saint-Fargeau presented a new criminal code to the National Constituent Assembly.[22] He explained that it outlawed only "true crimes", and not "phony offences created by superstition, feudalism, the tax system, and [royal] despotism".[23] He did not list the crimes "created by superstition". The new penal code did not mention blasphemy, heresy, sacrilege, witchcraft, incest, or homosexuality, which led to these former offences being swiftly decriminalised. In 1810, a new criminal code was issued under Napoleon. As with the Penal Code of 1791, it did not contain provisions for religious crimes, incest, or homosexuality.

After an overhaul of the entire legal system, the new code of civil procedure was adopted in 1806.
The commercial code (code de commerce [fr]) was adopted in 1807.[24] The kernel of the commercial code is the Book III, "Of The Different Modes of Acquiring Property", of the Napoleonic Code, which sets out norms for contracts and transactions.
Code d'instruction: In 1808, the code d'instruction criminelle was published, laying out criminal procedure. The parlement system from before the Revolution, had been much abused, and the criminal courts established by the Revolution were complex and ineffective, subject to many local pressures. The genesis of this code resulted in much debate and the basis of the modern inquisitorial system of criminal courts in France and many civil law countries. It has significantly changed since, especially with regard to the rights of the defendant.[25]
The French Revolution's Declaration of the Rights of Man and of the Citizen enunciated the presumption of innocence until found guilty. Concerned by the possibility of arbitrary arrest and detention, or excessive remand, Napoleon remarked that care should be taken to preserve personal freedoms, especially before the Imperial Court: "these courts would have a great strength, they should be prohibited from abusing this situation against weak citizens without connections."[26] However, remand still was usual for defendants suspected of serious crimes such as murder.

The possibility of lengthy remand periods was one criticism, particularly voiced in common law countries, of the Napoleonic Code and its de facto presumption of guilt. Another reason was the combination of magistrate and prosecutor into a single role.[27] However, with the work of the juge d'instruction accomplished, the trial itself did not have the same de jure presumption of guilt; for instance, the juror's oath explicitly required jurors not betray the interests of the defendants or ignore their defence.

The rules governing court proceedings gave significant power to the prosecution; however, criminal justice in European countries in those days tended to repression. For instance, it was only in 1836 that prisoners charged with a felony were given a formal right to counsel in England. In comparison, article 294 of the Napoleonic Code of Criminal Procedure[clarification needed] allowed the defendant access to a lawyer before a Cour d'assises, and mandated the court to appoint a lawyer for the defendants who did not have one. (Failing to do so nullified the proceedings.)

Whether or not the Cour d'assises, which judges severe crimes, should operate with a jury was a topic of considerable controversy. Napoleon supported jury trials (or petit jury), and they were finally adopted. On the other hand, Napoleon opposed the indictment jury ("grand jury" of common law countries), and preferred to assign this task to the criminal division of the Court of Appeals. Special courts were created to judge criminals who might intimidate the jury.

French codes in the 21st century
The French codes, now more than 60 in number,[28] are frequently amended, as well as judicially re-interpreted. Therefore, for over a century all of the codes in force have been documented in the annually revised editions published by Dalloz (Paris).[29] These editions consist of thorough annotations, with references to other codes, relevant statutes, judicial decisions (even if unpublished), and international instruments. The "small (petit)" version of the Civil Code in this form is nearly 3,000 pages, available in print and online. Additional material, including scholarly articles, is added in the larger "expert (expert)" version and the still larger "mega (méga)" version, both of which are available in print and on searchable CD-ROM. By this stage, it has been suggested, the Civil Code has become "less a book than a database".[30]

The sheer number of codes, together with digitisation, led the Commission supérieure de codification to reflect in its annual report for 2011:

The Commission observes that the age of drawing up new codes is probably reaching its end. The aim of a nearly complete codification of the law is no longer pursued, for three reasons: firstly, the technical developments by which texts are provided in non-physical form offer to users modes of access that are comparable in many ways to those available through a code; secondly, the creation of new codes encounters a kind of law of diminishing returns in that, the more progress that is made in the development of new codes, the trickier it becomes to determine in which code particular provisions should be located; and, finally, it is clear that certain kinds of provision [...] are unsuitable for codification, since codification makes sense only when it involves provisions that possess sufficient generality.[31]

A year later, the Commission recommended that, after its current codification projects were completed, there should not be any further codes; an additional reason was government delay in publishing reforms that the Commission had completed.[32] The government responded encouragingly in March 2013, but the Commission complains that this has not been followed through; in particular, that the government has abandoned its plan for a public service code (code général de la fonction publique).[33]

Codes in other countries

This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (February 2012) (Learn how and when to remove this message)
Even though the Napoleonic Code was not the first civil code, it was the first modern legal code to be widely adopted in Europe, and it influenced the law of many of the countries formed during and after the Napoleonic Wars.[7][2][34] In the German regions on the west bank of the Rhine (Rhenish Palatinate and Prussian Rhine Province), the former Duchy of Berg and the Grand Duchy of Baden, the Napoleonic Code was influential until the introduction of the Bürgerliches Gesetzbuch in 1900 as the first common civil code for the entire German Empire.[35]

A number of factors have been shown by Arvind and Stirton to have had a determinative role in the decision by the German states to receive the code, including territorial concerns, Napoleonic control and influence, the strength of central state institutions, a feudal economy and society, rule by liberal (enlightened despotic) rulers, nativism among the governing elites, and popular anti-French sentiment.[35]

A civil code with Napoleonic code influences was also adopted in 1864 in Romania, and remained in force until 2011.[36]

The term "Napoleonic Code" is also used to refer to legal codes of other jurisdictions that are influenced by the French Code Napoléon, especially the Civil Code of Lower Canada (replaced in 1994 by the Civil Code of Quebec), mainly derived from the Coutume de Paris, which the British continued to use in Canada following the 1763 Treaty of Paris. However, most of the laws in Latin American countries are not heavily influenced on the Napoleonic Code, as the Spanish and Portuguese versions of the civil code formed the foundation of the Latin American legal systems e.g. the Chilean, Mexican,[37] and Puerto Rican civil codes.[38]

In Mauritius, the Civil Code, which originates from the Napoleonic Code, represents an important primary source of law and provides for the rights of individuals, matrimonial regimes, contract law, and property law, amongst others.[39] The French Civil Code was extended to Mauritius under the title Code Napoléon by decree of Charles Mathieu Isidore Decaen, Capitaine-General, on 21 April 1808.[40] The Code was modified and embodied in Chapter 179 of the Revised Laws of Mauritius 1945, edited by Sir Charlton Lane, former Chief Justice of Mauritius. The 1808 decree was repealed by Act 9 of 1983, but the Revision of Laws Act which was enacted in 1974, made provision, in section 7, for the publication of the Code under the title "Code Civil Mauricien."[41]

In the United States, the legal system is largely based on English common law. But the state of Louisiana is unique in having a strong influence from French and Spanish legal traditions on its civil code. Spanish and French colonial forces quarreled over Louisiana during most of the 1700s, with Spain ultimately ceding the territory to France in 1800, which in turn sold the territory to the United States in 1803.[42] The 10th Amendment to the U.S. Constitution grants states control of laws not specifically given to the federal government, so Louisiana's legal system retains many French elements. Examples of the practical legal differences between Louisiana and the other states include the bar exam and legal standards of practice for attorneys in Louisiana being significantly different from other states; Louisiana is the only U.S. state to practice forced inheritance of an estate; additionally, some of Louisiana's laws clash with the Uniform Commercial Code practiced by the other 49 states
The Civil Code of Lower Canada (French: Code civil du Bas-Canada) was a law that was in effect in Lower Canada on 1 August 1866 and remained in effect in Quebec until repealed and replaced by the Civil Code of Quebec on 1 January 1994. The Code replaced a mixture of French law and English law that had arisen in Lower Canada since the creation of the British Province of Quebec by the Royal Proclamation of 1763, as modified by the Quebec Act in 1774.

Before the Code
French colonial era
From 1608 to 1664, the first colonists of New France followed the customary law (French: coutume) in effect for their province of origin in France. In 1664, the King of France decreed in Article 33 of the decree establishing the French West India Company (French: l'Édit d'établissement de la compagnie des Indes occidentales) that the Custom of Paris would serve as the main source of law throughout New France. Later, authorities went on to add le droit français de la métropole, that is, French law. This included royal decrees and ordinances (ordonnances royales), canon law relating to marriages, and Roman law relating to obligations, e.g., contracts and torts. Also in force were the ordinances issued by Royal Intendants (ordonnances des intendants) and the orders and judgments handed down by the Conseil supérieur.

The Royal Intendant was responsible for administering justice in the colony, and lawyers were barred from practicing in the colony. Most disputes were resolved by local notaries or local parish priests through arbitration in a manner much as had been done in ancient Rome. While the reliance on feudal French law meant that New France was divided into fiefs (seigneuries), the manorial lords (or seigneurs) were not entitled to the same judicial discretion in New France as they had in France; as it was, all criminal jurisdiction went to the Intendant. Therefore, while the Custom of Paris was the law of New France, there were few resources available for colonists to actually enforce that law.

Under the British Empire
Following France's relinquishment of Canada in favour of Guadeloupe in the Treaty of Paris, Canada came under British law. However, the seigneurial system of land tenure continued to be applied uniformly throughout the province. In 1774, as a result of a ruling by the British courts in Campbell v Hall about the status of legal systems found in acquired territories, the British Parliament passed the Quebec Act, which preserved French civil law for private law while keeping and reserving English common law for public law, including criminal prosecution. As a result, modern-day Quebec is one of a handful of jurisdictions in the world where two legal systems co-exist.

The Quebec Act was opposed by the English minority who believed that British citizens should be governed by English law. The Constitutional Act of 1791 resolved the dispute through the creation of Upper Canada west of the Ottawa River (subject to English common law) and Lower Canada around the St. Lawrence River (where civil law was maintained).

The need for codification

René-Édouard Caron
The practice of civil law in Lower Canada became quite complex by the middle of the 19th century, because of the multiple sources of law that needed to be drawn upon — most only available in French. As identified by René-Édouard Caron, the "law of the land" included:[1]

the Custom of Paris as it was in 1663
during 1663–1759, edicts and ordinances of the French Crown that applied to Canada[a]
during 1663–1759, ordinances of the Conseil supérieur
laws, edicts and ordinances issued by the French Crown for France that were registered with the Conseil supérieur
statutes of the British Parliament passed since the Conquest for Canada, or which specifically named Canada
during 1759–1764, laws passed by the British military government prior to the Treaty of Paris
during 1764–1791, laws passed by the Legislative Council of Quebec
Provincial Statutes of Lower Canada, 1791–1840
Ordinances of the Special Council of Lower Canada, 1838–1841
from 1840, Acts passed by the Parliament of the Province of Canada applicable to Lower Canada
English criminal laws as they existed at the passage of the Quebec Act 1774 as amended
for matters not treated in the above categories:
pre-revolutionary French legal writers, such as Robert Joseph Pothier, Jean Domat, and Angers
Canadian legal writers, such as Doucet, Crémazie, Louis-Hippolyte LaFontaine, and Bonner
case law incorporating French case law and judgments published in Canadian law reports
English public law applicable throughout the British Empire affecting the rights of British subjects

Désiré Girouard
In 1859, Désiré Girouard (later a judge of the Supreme Court of Canada) noted:

There is nothing more uncertain than the actual law of Lower Canada, nothing more confused than the state of Canadian law.[2]

Creation
In 1857, the Legislative Assembly of the Province of Canada passed An Act respecting the Codification of the Laws of Lower Canada relative to Civil matters and Procedure,[3][4] to authorize the codification of the civil law then currently in force in Lower Canada. The Act's preamble declared:

WHEREAS the laws of Lower Canada in Civil Matters are mainly those which, at the time of the cession of the country to the British Crown, were in force in that part of France then governed by the Custom of Paris, modified by the Provincial Statutes, or by the introduction of portions of the Law of England in peculiar cases; and it therefore happens, that the great body of the Laws; in that division of the Province, exist only in a language which is not the mother tongue of the inhabitants thereof of British origin, while other portions are not to be found in the mother tongue of those of French origin and whereas the laws and Customs in force in France, at the period above mentioned, have there been altered and reduced to one general Code, so that the old laws still in force in Lower Canada are no longer reprinted or commented upon in France, and it is becoming more and more difficult to obtain copies of them, or of the commentaries upon them; And whereas the reasons aforesaid, and the great advantages which have resulted from Codification, as well in France as in the State of Louisiana, and other places, render it manifestly expedient to provide for the Codification of the Civil Laws of Lower Canada:

The Act authorized the creation of a codification commission, which consisted of three commissioners and two secretaries, all drawn from the Bar of Lower Canada.
Royal assent is the method by which a monarch formally approves an act of the legislature, either directly or through an official acting on the monarch's behalf. In some jurisdictions, royal assent is equivalent to promulgation, while in others that is a separate step. Under a modern constitutional monarchy, royal assent is considered little more than a formality. Even in nations such as the United Kingdom, Norway, the Netherlands, Liechtenstein and Monaco which still, in theory, permit their monarch to withhold assent to laws, the monarch almost never does so, except in a dire political emergency or on advice of government. While the power to veto by withholding royal assent was once exercised often by European monarchs, such an occurrence has been very rare since the eighteenth century.

Royal assent is typically associated with elaborate ceremony. In the United Kingdom the Sovereign may appear personally in the House of Lords or may appoint Lords Commissioners, who announce that royal assent has been granted at a ceremony held at the Palace of Westminster for this purpose. However, royal assent is usually granted less ceremonially by letters patent. In other nations, such as Australia, the governor-general (as the Monarch's representative) has the right to dissolve the parliament[1] and to sign a bill.[citation needed] In Canada, the governor general may give assent either in person at a ceremony in the Senate or by a written declaration notifying Parliament of their agreement to the bill.

Usage
The monarch would today not veto a bill, except on ministerial advice. Robert Blackburn suggested the monarch's granting of royal assent is now limited to due process and is a certification that a bill has passed all established parliamentary procedures,[2] whereas Rodney Brazier argued that a monarch can still refuse royal assent to a bill that "sought to subvert the democratic basis of the constitution". However, Brazier went on to admit doing such a thing would lead to "grave difficulties of definition" and it would be better if the monarch sought a different method of expressing their concern.[3] The only situation in which royal assent could be denied would be if a bill had been passed by the legislative houses or house against the wishes of the cabinet and the royal assent stage offered the latter with a last-ditch opportunity to prevent the bill from becoming law.[4]

United Kingdom
See also: Royal Assent Act 1967
Before the Royal Assent by Commission Act 1541 allowed for delegation of the power to Lords Commissioners, assent was always required to be given by the Sovereign in person before Parliament.[5] The last time it was given by the Sovereign in person in Parliament was during the reign of Queen Victoria at a prorogation on 12 August 1854.[6][a] The Act was repealed and replaced by the Royal Assent Act 1967. However section 1(2) of that Act does not prevent the Sovereign from declaring assent in person if he or she so desires.

Royal assent is the final step required for a parliamentary bill to become law. Once a bill is presented to the Sovereign, he or she has the following formal options:

grant royal assent, thereby making the bill an Act of Parliament.
delay the bill's assent through the use of reserve powers, thereby invoking a veto[8]
refuse royal assent on the advice of his or her ministers.[9]
The last bill that was refused assent was the Scottish Militia Bill during Queen Anne's reign in 1708.[10]

Erskine May's Parliamentary Practice advises "...and from that sanction they cannot be legally withheld", meaning that bills must be sent for royal assent, not that it must be given.[11] However, some authorities have stated that the Sovereign no longer has the power to withhold assent from a bill against the advice of ministers.[12][13]

Under modern constitutional conventions, the Sovereign generally acts on, and in accordance with, the advice of his or her ministers.[14] However, there is some disagreement among scholars as to whether the monarch should withhold royal assent to a bill if advised to do so by his or her ministers.[15]

Since these ministers most often enjoy the support of Parliament and obtain the passage of bills, it is improbable that they would advise the Sovereign to withhold assent. Hence, in modern practice, the issue has never arisen, and royal assent has not been withheld.[8] This possibility did arise during the early days of the premiership of Boris Johnson while the UK was negotiating a Brexit agreement with the EU. The Speaker of the House of Commons had allowed debate on a bill against the government's wishes, and the government of the day was effectively in a minority on the most pressing parliamentary issue at the time. As such, there were rumours that the prime minister might advise the then-Sovereign, Elizabeth II, to withhold assent on an unfavourable bill.[16]

Historical development
Originally, legislative power was exercised by the sovereign acting on the advice of the Curia regis, or royal council, in which senior magnates and clerics participated and which evolved into Parliament.[17] In 1265, the Earl of Leicester irregularly called a full parliament without royal authorisation.[18] Membership of the so-called Model Parliament, established in 1295 under Edward I, eventually came to be divided into two branches: bishops, abbots, earls, and barons formed the House of Lords, while the two knights from each shire and two burgesses from each borough led the House of Commons.[19] The King would seek the advice and consent of both houses before making any law.[20]

During Henry VI's reign, it became regular practice for the two houses to originate legislation in the form of bills, which would not become law unless the Sovereign's assent was obtained, as the Sovereign was, and still remains, the enactor of laws. Hence, all Acts include the clause "Be it enacted by the King's (Queen's) most Excellent Majesty, by and with the advice and consent of the Lords Spiritual and Temporal, and Commons, in this present Parliament assembled, and by the authority of the same, as follows...".[20] The Parliament Acts 1911 and 1949 provide a second potential preamble if the House of Lords were to be excluded from the process.

The power of Parliament to pass bills was often thwarted by monarchs. Charles I dissolved Parliament in 1629, after it passed motions and bills critical of—and seeking to restrict—his arbitrary exercise of power. During the eleven years of personal rule that followed, Charles performed legally dubious actions such as raising taxes without Parliament's approval.[21]

The form of the Coronation Oath taken by monarchs up to and including James I and Charles I included a promise (in Latin) to uphold the rightful laws and customs quas vulgus elegerit.[b] There was a controversy over the meaning of this phrase: the verb elegerit is ambiguous, representing either the future perfect ("which the common people shall have chosen"), or perfect subjunctive ("which the common people may have chosen"). Charles I, adopting the latter interpretation, considered himself committed only to uphold those laws and customs that already existed at the time of his coronation.[23] The Long Parliament preferred the former translation, interpreting the oath as an undertaking to assent to any law passed by Parliament, as the representative of the "common people". The restoration Convention Parliament resolved the issue by removing the disputed phrase from the Oath.[24]

After the English Civil War, it was accepted that Parliament should be summoned to meet regularly, but it was still commonplace for monarchs to refuse royal assent to bills. The Sedition Act 1661 even made it a treasonable offence to suggest that Parliament had "a legislative power without the king".[24] In 1678, Charles II withheld his assent from a bill "for preserving the Peace of the Kingdom by raising the Militia, and continuing them in Duty for Two and Forty Days,"[25] suggesting that he, not Parliament, should control the militia.[26] William III made comparatively liberal use of the royal veto, withholding assent from five public bills between 1692 and 1696.[24] These were:

The Judges Bill (vetoed 1692) would have regulated the fees charged by judges, and removed the right of the monarch to dismiss judges at will, stipulating that a judge should hold his commission "on good behaviour". One contemporary observer reported that William's veto was recommended by the judges themselves, concerned that the regulation of their fees would deprive them of a lucrative source of income.[24]
The Royal Mines Bill (vetoed 1692) would have clearly defined the monarch's right to seize any mine containing gold or silver. A similar bill was again passed by Parliament and given royal assent in the following year.[24]
The Triennial Bill (vetoed 1693) would have ensured Parliament would meet annually, and that no parliament could last longer than three years. A similar law, without the requirement for annual parliamentary sessions, was approved by the king in 1694 and became law.[24]
The Place Bill (vetoed 1694) would have prevented members of Parliament from accepting any office or employment under the Crown without standing for re-election.[24] A similar provision was later approved by William as part of the Act of Settlement 1701.[27]
The Qualifications Bill (vetoed 1696) would have established property qualifications for members of Parliament.[24]
Carafano suggests that William III considered the royal veto "his personal legislative tool".[24] By contrast, the last Stuart monarch, Anne, withheld her assent from a bill just once. On 11 March 1708, she vetoed the Scottish Militia Bill on the advice of her ministers. No monarch has since withheld royal assent on a bill passed by Parliament.[28][29]

During the rule of the succeeding Hanoverian dynasty, power was gradually exercised more by Parliament and the government. The first Hanoverian monarch, George I, became heir presumptive and then king late in life. Speaking English as a second language and being at first unfamiliar with British politics and customs, he relied on his ministers to a greater extent than had previous monarchs. Later Hanoverian monarchs attempted to restore royal control over legislation: George III and George IV both openly opposed Catholic Emancipation[30][31] and asserted that to grant assent to a Catholic emancipation bill would violate the Coronation Oath, which required the sovereign to preserve and protect the established Church of England from papal domination, and would grant rights to individuals who were in league with a foreign power which did not recognise their legitimacy. However, George IV reluctantly granted his assent upon the advice of his ministers.[31] Thus, as the concept of ministerial responsibility has evolved, the power to withhold royal assent has fallen into disuse, both in the United Kingdom and in the other Commonwealth realms.

In 1914, George V took legal advice on withholding royal assent from the Government of Ireland Bill; then highly contentious legislation that the Liberal government intended to push through Parliament by means of the Parliament Act 1911. He decided not to withhold assent without "convincing evidence that it would avert a national disaster, or at least have a tranquillising effect on the distracting conditions of the time".[32]

It has been mooted that, in modern times, the government could advise the monarch to withhold royal assent, but that elected politicians should strive to avoid such a scenario.[33]

Scotland
Royal assent is the final stage in the legislative process for acts of the Scottish Parliament. The process is governed by sections 28, 32, 33, and 35 of the Scotland Act 1998.[34] After a bill has been passed, the Presiding Officer of the Scottish Parliament submits it to the monarch for royal assent after a four-week period, during which the Advocate General for Scotland, the Lord Advocate, the Attorney General or the Secretary of State for Scotland[35] may refer the bill to the Supreme Court of the United Kingdom (prior to 1 October 2009, the Judicial Committee of the Privy Council) for review of its legality. Royal assent is signified by letters patent under the Great Seal of Scotland as set out in The Scottish Parliament (Letters Patent and Proclamations) Order 1999 (SI 1999/737) and of which notice is published in the London, Edinburgh, and Belfast Gazettes.[36]

The authority of the Secretary of State for Scotland to prohibit the submission of an act of the Scottish Parliament for royal assent was first used in January 2023 for the Gender Recognition Reform (Scotland) Bill.[37]

Wales
Measures, which were the means by which the National Assembly for Wales passed legislation between 2006 and 2011, were assented to by Queen Elizabeth II by means of an Order in Council.[38][39] Section 102 of the Government of Wales Act 2006 required the Clerk to the Assembly to present measures passed by the assembly after a four-week period during which the Counsel General for Wales or the Attorney General could refer the proposed measure to the Supreme Court for a decision as to whether the measure was within the assembly's legislative competence. Following the referendum held in March 2011, in which the majority voted for the assembly's law-making powers to be extended,[40] measures were replaced by Acts of the Assembly.[41]

Northern Ireland
Under section 14 of the Northern Ireland Act 1998, a bill which has been approved by the Northern Ireland Assembly is presented to the monarch by the Secretary of State for Northern Ireland for royal assent after a four-week waiting period during which the Attorney General for Northern Ireland may refer the bill to the Supreme Court. Assent is given by means of letters patent in the following form set out in the Northern Ireland (Royal Assent to Bills) Order 1999.[42]

Between 1922 and 1972, bills passed by the Parliament of Northern Ireland were passed to the Governor of Northern Ireland for royal assent under the Government of Ireland Act of 1920, replacing the office of Lord Lieutenant.[43]

Jersey and Guernsey
The lieutenant governors of the Bailiwick of Jersey and the Bailiwick and Islands of Guernsey do not have the authority to grant assent, nor, as proxies, as the British Crown's representative, deliver assent, to legislation emanating from the respective legislatures of these islands. The States of Jersey Law 2005 abolishes the power of the lieutenant governor to directly impose a formal veto to a resolution of the States of Jersey.[44]

The equivalent of the royal assent is formally granted or formally refused on the formal advice of the Committee of Council for the Affairs of Jersey and Guernsey in pursuance of Queen Elizabeth II's Order-in-Council of 22 February 1952. A recent example when the equivalent of the royal assent was refused was in 2007, concerning reforms to the constitution of the Chief Pleas of Sark.[45] (A revised version of the proposed reforms was subsequently given the equivalent of the royal assent.[46])

Isle of Man
Special procedures apply to legislation passed by the Tynwald of the Isle of Man. Before the Lordship of the Island was purchased by the British Crown in 1765 (the Revestment), the assent of the Lord of Mann to a bill was signified by letter to the Governor.[47] After 1765, the equivalent of the royal assent was at first signified by the letter from the Secretary of State to the Governor;[48] but, during the British Regency, the practice began of granting the equivalent of the royal assent to Manx legislation by Orders in Council,[49] which continues to this day, though limited to exceptional cases since 1981. That year an Order in Council delegated to the lieutenant governor the power to grant royal assent to bills passed by Tynwald. The lieutenant governor must however refer any bill impacting on reserved powers (defence, foreign relations, nationality law, the relationship between the island and the United Kingdom and any matters relating to the monarch) to the British government for advice, on which he is required to act.[50]

Since 1993, the Sodor and Man Diocesan Synod of the Church of England within the Province of York has had power to enact measures making provision "with respect to any matter concerning the Church of England in the Island". If approved by the Tynwald, a measure "shall have the force and effect of an Act of Tynwald upon the Royal Assent thereto being announced to the Tynwald".[51] Between 1979 and 1993, the Synod had similar powers, but limited to the extension to the Isle of Man of measures of the General Synod.[52] Before 1994, the equivalent of the royal assent was granted by Order in Council, as for a bill, but the power to grant the equivalent of the royal assent to measures has now been delegated to the lieutenant governor.[53] A Measure does not require promulgation.[54]

Relationship to royal consent
Main article: Royal Consent
King's Consent and Prince's Consent are distinct from royal assent. They are required only for bills affecting the royal prerogative and the personal property and "personal interests" of the monarch, and are granted before parliament has debated or voted to pass a bill. They are internal parliamentary rules of procedure that could, in principle, be dispensed with by parliament. Consent is always granted on the advice of the government; the monarch never takes the decision to withhold consent.

Other Commonwealth realms
In Commonwealth realms other than the UK, royal assent is granted or withheld either by the realm's sovereign or, more frequently, by the representative of the sovereign, the governor-general.[55] In Australia and Canada, which are federations, assent in each state or province is granted or withheld by the relevant governor or lieutenant governor, respectively.

In Australia, in the special case of a bill proposing to amend the constitution, the bill is submitted to the electorate in a referendum and must receive majority support before receiving royal assent. All other bills passed normally by the Parliament become acts of Parliament once they have received royal assent.[56]

Canada
For Canada, the lieutenant governors may defer assent to the governor general,[57] who may defer assent to federal bills to the sovereign.[58] If the governor general is unable to give assent, it can be done by a deputy, specifically a justice of the Supreme Court of Canada. Through Canadian history, royal assent has been withheld by a lieutenant governor approximately 90 times, the last occurring in Saskatchewan in 1961.[59]

It is not actually necessary for the governor general to sign a bill passed by a legislature, the signature being merely an attestation. In each case, the parliament must be apprised of the granting of assent before the bill is considered to have become law.[60] Two methods are available: the sovereign's representatives may grant assent in the presence of both houses of parliament. Alternatively, each house may be notified separately, usually by the speaker of that house. Both houses must be notified on the same day. Notice to the House of Commons while it is not in session may be given by way of publishing a special issue of the Journals of the House of Commons. The Senate must be sitting and the governor general's letter read aloud by the speaker.[60]

Development
While royal assent has not been withheld for a bill backed by the government in the United Kingdom since 1708, it has often been withheld in British colonies and former colonies by governors acting on royal instructions. In the United States Declaration of Independence, colonists complained that George III "has refused his Assent to Laws, the most wholesome and necessary for the public good [and] has forbidden his Governors to pass Laws of immediate and pressing importance, unless suspended in their operation till his Assent should be obtained; and when so suspended, he has utterly neglected to attend to them."[61]

Since the Balfour Declaration of 1926 and the Statute of Westminster 1931, all the Commonwealth realms have been sovereign kingdoms, the monarch and governors-general acting solely on the advice of the local ministers, who generally maintain the support of the legislature and are the ones who secure the passage of bills. They, therefore, are unlikely to advise the sovereign, or his or her representative, to withhold assent. The power to withhold the royal assent was exercised by Alberta's Lieutenant Governor, John C. Bowen, in 1937, in respect of three bills passed in the legislature dominated by William Aberhart's Social Credit party. Two bills sought to put banks under the authority of the province, thereby interfering with the federal government's powers. The third, the Accurate News and Information Bill, purported to force newspapers to print government rebuttals to stories to which the provincial cabinet objected. The unconstitutionality of all three bills was later confirmed by the Supreme Court of Canada and by the Judicial Committee of the Privy Council.[62]

In Australia, technical issues arose with the royal assent in both 1976 and 2001. In 1976, a bill originating in the House of Representatives was mistakenly submitted to the governor-general and assented to. However, it was later discovered that it had not been passed by the Senate. The error arose because two bills of the same title had originated from the House. The governor-general revoked the first assent, before assenting to the bill which had actually passed the Senate and the House. The same procedure was followed to correct a similar error that arose in 2001.[63]

Ceremony
United Kingdom

Start of the parchment roll of the Reform Act 1832, with the clerk's record of the royal assent of King William IV written above the bill, reading in full Le Roy le Veult. Soit baillé aux Seigneurs. A cette Bille avecque des amendemens les Seigneurs sont assentuz. A ces Amendemens les Communes sont assentuz.
In the United Kingdom, a bill is presented for royal assent after it has passed all the required stages in both the House of Commons and the House of Lords. Under the Parliament Acts 1911 and 1949, the House of Commons may, under certain circumstances, direct that a bill be presented for assent despite lack of passage by the House of Lords.[64][65]

A list of all bills that have thus passed Parliament is drawn up by the Clerk of the Crown in Chancery; this list is then approved by the Clerk of the Parliaments. (The Prime Minister, other ministers, and Privy Counsellors do not normally have any involvement in drawing up the list.) The Clerk of the Crown then prepares letters patent listing all the relevant bills, which are then signed by the monarch.[66]

Officially, assent is granted by the sovereign or by Lords Commissioners authorised to act by letters patent. Royal assent may be granted in parliament or outside parliament; in the latter case, each house must be separately notified before the bill takes effect.

The Clerk of the Parliaments, the chief official of the House of Lords, traditionally pronounces a formula in Anglo-Norman Law French, indicating the sovereign's decision. The granting of royal assent to a supply bill is indicated with the words "Le Roy remercie ses bons sujets, accepte leur benevolence, et ainsi le veult",[8] translated as "The King thanks his good subjects, accepts their bounty, and so wills it." For other public or private bills, the formula is simply "Le Roy le veult" ("the King wills it"). For personal bills, the phrase is "Soit fait comme il est désiré" ("let it be done as it is desired"). The appropriate formula for withholding assent is the euphemistic "Le Roy s'avisera" ("the King will consider it").[67]

When the sovereign is female, Le Roy is replaced by La Reyne.

Before the reign of Henry VIII, the sovereign always granted his or her assent in person. The sovereign, wearing the Crown, would be seated on the throne in the Lords chamber, surrounded by heralds and members of the royal court—a scene that nowadays is repeated only at the annual State Opening of Parliament. The Commons, led by their Speaker, would listen from the Bar of the Lords, just outside the chamber. The Clerk of the Parliaments presented the bills awaiting assent to the monarch, save that supply bills were traditionally brought up by the Speaker. The Clerk of the Crown, standing on the sovereign's right, then read aloud the titles of the bills (in earlier times, the entire text of the bills). The Clerk of the Parliaments, standing on the sovereign's left, responded by stating the appropriate Norman French formula.[68]


Henry VIII introduced a new method of granting royal assent.
A new device for granting assent was created during the reign of King Henry VIII. In 1542, Henry sought to execute his fifth wife, Catherine Howard, whom he accused of committing adultery; the execution was to be authorised not after a trial but by a bill of attainder, to which he would have to personally assent after listening to the entire text. Henry decided that "the repetition of so grievous a Story and the recital of so infamous a crime" in his presence "might reopen a Wound already closing in the Royal Bosom".[69] Therefore, Parliament inserted a clause into the Act of Attainder, providing that assent granted by Commissioners "is and ever was and ever shall be, as good" as assent granted by the sovereign personally.[70] The procedure was used only five times during the 16th century, but more often during the 17th and 18th centuries, especially when George III's health began to deteriorate. Queen Victoria became the last monarch to personally grant assent in 1854.[71][72]

When granting assent by commission, the sovereign authorises three or more (normally five) lords who are privy counsellors to declare assent in his or her name. The Lords Commissioners, as the monarch's representatives are known, wear scarlet parliamentary robes and sit on a bench between the throne and the Woolsack. The Lords Reading Clerk reads the commission aloud; the senior commissioner then states, "My Lords, in obedience to His Majesty's Commands, and by virtue of the Commission which has been now read, We do declare and notify to you, the Lords Spiritual and Temporal and Commons in Parliament assembled, that His Majesty has given His Royal Assent to the several Acts in the Commission mentioned."[73][74]

During the 1960s, the ceremony of assenting by commission was discontinued and is now only employed once a year, at the end of the annual parliamentary session. In 1960, the Gentleman Usher of the Black Rod arrived to summon the House of Commons during a heated debate and several members protested against the disruption by refusing to attend the ceremony. The debacle was repeated in 1965; this time, when the Speaker left the chair to go to the House of Lords, some members continued to make speeches. As a result, the Royal Assent Act 1967 was passed, creating an additional form for the granting of royal assent. As the attorney-general explained, "there has been a good deal of resentment not only at the loss of Parliamentary time that has been involved but at the breaking of the thread of a possibly eloquent speech and the disruption of a debate that may be caused."[75]

Under the Royal Assent Act 1967, royal assent can be granted by the sovereign in writing, by means of letters patent, that are presented to the presiding officer of each house of Parliament.[68] Then, the presiding officer makes a formal, but simple statement to the house, acquainting each house that royal assent has been granted to the acts mentioned. Thus, unlike the granting of royal assent by the monarch in person or by royal commissioners, the method created by the Royal Assent Act 1967 does not require both houses to meet jointly for the purpose of receiving the notice of royal assent. The standard text of the letters patent is set out in The Crown Office (Forms and Proclamations Rules) Order 1992,[76] with minor amendments in 2000. In practice this remains the standard method, a fact that is belied by the wording of the letters patent for the appointment of the Royal Commissioners and by the wording of the letters patent for the granting of royal assent in writing under the 1967 Act ("... And forasmuch as We cannot at this time be present in the Higher House of Our said Parliament being the accustomed place for giving Our Royal Assent...").[77]

Independently of the method used to signify royal assent, it is the responsibility of the Clerk of the Parliaments, once the assent has been duly notified to both houses, not only to endorse the act in the name of the monarch with the formal Norman French formula, but to certify that assent has been granted.[78] The Clerk signs one authentic copy of the bill and inserts the date (in English) on which the assent was notified to the two houses after the title of the act.[79]

Australia and New Zealand
In Australia, the formal ceremony of granting assent in parliament has not been regularly used since the early 20th century. Today, the bill is sent to the governor's or the governor-general's residence by the house in which it originated. The governor-general then signs the bill, and notifies the president of the Senate and the speaker of the House of Representatives, who notify their respective houses of the governor-general's action.[80] A similar practice is followed in New Zealand, where the governor-general has not granted the royal assent in person in parliament since 1875.[80]

Canada

Kevin S. MacLeod as Usher of the Black Rod in 2009. Black Rod is a key element of the royal assent ceremony in Canada as in Britain.
In Canada, the traditional ceremony for granting assent in Parliament was regularly used until the 21st century, long after it had been discontinued in the United Kingdom and other Commonwealth realms. One result, conceived as part of a string of acts intended to demonstrate Canada's status as an independent realm, was that King George VI personally assented to nine bills of the Canadian Parliament during his tour of Canada in 1939—85 years after his great-grandmother, Queen Victoria, had last granted royal assent personally in the United Kingdom. Under the Royal Assent Act, 2002, the alternative practice of granting assent in writing, with each house being notified separately, was brought into force. The speaker of the Senate or a representative reads to the senators the letters from the governor general regarding the written declaration of royal assent.[81] As the act provides, royal assent is to be signified—by the governor general or by a deputy, usually a Justice of the Supreme Court.[71]

The royal assent ceremony takes place in the Senate, as the sovereign is traditionally barred from the House of Commons.[82] On the day of the event, the speaker of the Senate will read to the chamber a notice from the secretary to the governor general indicating when the viceroy or a deputy thereof will arrive. The Senate thereafter cannot adjourn until after the ceremony. The speaker moves to sit beside the throne. The mace bearer, with mace in hand, stands adjacent to him or her, and the governor general enters to take the speaker's chair.[83]

The usher of the Black Rod is then commanded by the speaker to summon the members of Parliament, who follow black rod back to the Senate, the sergeant-at-arms carrying the mace of the House of Commons. In the Senate, those from the Commons stand behind the bar, while black rod proceeds to stand next to the governor general, who then nods his or her head to signify royal assent to the presented bills (which do not include supply bills). Once the list of bills is complete, the clerk of the Senate states: "in his [or her] majesty's name, his [or her] excellency the governor general [or the deputy] doth assent to these bills."[83]

If there are any supply bills to receive royal assent, the speaker of the House of Commons will read their titles and the Senate clerk repeats them to the governor general, who nods his or her head to communicate royal assent. When these bills have all been assented to, the clerk of the Senate recites "in his [or her] majesty's name, his [or her] excellency the governor general [or the deputy] thanks his [or her] loyal subjects, accepts their benevolence, and assents to these bills." The governor general or his or her deputy then depart Parliament.[84]

Other countries
In some monarchies—such as Belgium, Denmark, Japan, Malaysia, the Netherlands,[85] Norway, Spain, and Thailand—promulgation is required as well as royal assent. In Sweden, however, the monarch was removed from the process in 1975; instead, the government (i.e. the cabinet chaired by the Prime Minister) officially promulgates laws. In both cases, however, the process of assent and promulgation is usually a formality, whether by constitutional convention or by an explicit provision of the constitution.

Belgium
In Article 109 of the constitution: "The King sanctions and promulgates laws". In Belgium, the royal assent is called sanction royale / koninklijke bekrachtiging (Royal Sanction), and is granted by the King signing the proposed statute (and a minister countersigning it). The Belgian constitution requires a theoretically possible refusal of royal sanction to be countersigned—as any other act of the monarch—by a minister responsible before the House of Representatives. The monarch promulgates the law, meaning that he or she formally orders that the law be officially published and executed. In 1990, when King Baudouin advised his cabinet he could not, in conscience, sign a bill decriminalising abortion (a refusal patently not covered by a responsible minister), the Council of Ministers, at the King's own request, declared Baudouin incapable of exercising his powers. In accordance with the Belgian constitution, upon the declaration of the Sovereign's incapacity, the Council of Ministers assumed the powers of the head of state until parliament could rule on the King's incapacity and appoint a regent. The bill was then assented to by all members of the Council of Ministers "on behalf of the Belgian People".[86] In a joint meeting, both houses of parliament declared the King capable of exercising his powers again the next day.[87]

Japan
Articles 6 and 7 of the Constitution of Japan mention the decisions of the parliament that require the approval of the Emperor. These are some of the so-called "acts of state" (国事行為, kokuji-kōi), and according to Article 3 of the Constitution, acts of state require the advice and approval of the Cabinet, which is the responsibility of the Cabinet.[88]

Jordan
The constitution of Jordan grants its monarch the right to withhold assent to laws passed by its parliament. Article 93 of that document gives the Jordanian Sovereign six months to sign or veto any legislation sent to him from the National Assembly. If he vetoes it within that timeframe, the assembly may override his veto by a two-thirds vote of both houses. Otherwise, the law does not go into effect, but it may be reconsidered in the next session of the assembly. If the monarch fails to act within six months of the bill being presented to him, it becomes law without his signature.[89]

Luxembourg
While Article 34 of the constitution of Luxembourg formerly required the grand duke or duchess to sanction and promulgate a new law for it to take effect, the required sanction was removed in 2008, after Grand Duke Henri informed his prime minister that he could not in good conscience assent to a bill to permit euthanasia in the country. The subsequent constitutional amendment removed the need for assent while retaining the need for the Grand Duke to promulgate new laws.[90] The Grand-Duke's signature is still required, but does not imply assent, only promulgation (announcement that the law has been enacted by Parliament).[91] The Grand-Duke did sign the Euthanasia Act under this new constitutional arrangement.[92]

Malaysia
Article 66(3) of the Federal Constitution of Malaysia provides that after a bill was passed by both Houses of Parliament, it shall be presented to the Yang di-Pertuan Agong (King of Malaysia) for his assent before being gazetted in order to become law. However, since 1983, if a bill does not received royal assent within 30 days after it was presented to the King, the bill will automatically become law as per Article 66(4A) of the Constitution.[93][94] Likewise, since 1994, if a Ruler of a Malaysian states does not grant his assent to a bill passed by the state Legislature within the 30 days period, the bill will automatically become law. As of 2016, the only federal law that failed to receive royal assent but still become law as per Article 66(4A) is the National Security Council Act 2016.[94]

Norway
Articles 77–79 of the Norwegian constitution specifically grant the monarch of Norway the right to withhold royal assent from any bill passed by the Storting.[95] Should the monarch ever choose to exercise this privilege, Article 79 provides a means by which his veto may be over-ridden: "If a Bill has been passed unaltered by two sessions of the Storting, constituted after two separate successive elections and separated from each other by at least two intervening sessions of the Storting, without a divergent Bill having been passed by any Storting in the period between the first and last adoption, and it is then submitted to the King with a petition that His Majesty shall not refuse his assent to a Bill which, after the most mature deliberation, the Storting considers to be beneficial, it shall become law even if the Royal Assent is not accorded before the Storting goes into recess."[95]

Spain
In Part II of the 1978 Spanish constitution, among provisions concerning the Crown, Article 62(a) invests the sanction (i.e. Royal Assent) and promulgation of laws with the monarch of Spain. Chapter 2 of Part III, concerning the Drafting of Bills, outlines the method by which bills are passed. According to Article 91, the monarch shall give his or her assent and promulgate the new law within fifteen days of passage of a bill by the Cortes Generales. Article 92 invests the monarch with the right to call for a referendum, on the advice of the president of the government (commonly referred to in English as the prime minister) and the authorisation of the cortes.

No constitutional provision allows the monarch to directly veto legislation; however, neither does the constitution prohibit the Sovereign from withholding royal assent. When the Spanish media asked King Juan Carlos I if he would endorse the bill legalising same-sex marriages, he answered: "Soy el Rey de España y no el de Bélgica" ("I am the King of Spain and not that of Belgium")—a reference to King Baudouin of Belgium, who had refused to sign the Belgian law legalising abortion.[96] The King gave royal assent to Law 13/2005 on 1 July 2005; the law was gazetted in the Boletín Oficial del Estado on 2 July and came into effect on 3 July 2005.[97]

Tonga
Articles 41 and 68 of the constitution empower the King to withhold royal assent from bills adopted by the Legislative Assembly.[98] In 2010, the kingdom moved towards greater democracy, with King George Tupou V saying that he would be guided by his prime minister in the exercising of his powers. Nonetheless, this does not preclude an independent royal decision to exercise a right of veto. In November 2011, the assembly adopted an Arms and Ammunitions (Amendment) Bill, which reduced the possible criminal sentences for the illicit possession of firearms. The bill was adopted by ten votes to eight. Two members of the assembly had recently been charged with the illicit possession of firearms. The Prime Minister, Lord Tuʻivakanō, voted in favour of the amendment. Members of the opposition denounced the bill and asked the King to veto it, which he did in December.[99][100][101][102]
